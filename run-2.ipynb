{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To play around\n",
    "You can just head to the section after results and load either the weighed_backup.csv or backup.csv to use the results from the cross validation, no need to run it through again.\n",
    "\n",
    "### Changes from run-1\n",
    "\n",
    "#### Test data\n",
    "* Previously we used cross-validation to select the best model, and tested that model on data (opus 131) that we had kept apart from the beginning.\n",
    "* The scores achieved when predicting on opus 131 were our final results.\n",
    "* This time we train/validate on all data and take the final cross-validation scores as our results.\n",
    "\n",
    "#### Crossvalidation\n",
    "* Previously we simply took all sequences in the train/validate set, shuffled them and trained/validated with a 80/20 split.\n",
    "* This time we instead shuffle the opuses (opi?) before generating the sequences, with the idea that this could hint at how patterns generalize across opuses with. So we basically have leave one (opus) out cross validation.\n",
    "\n",
    "#### Input\n",
    "* Previously we grouped similar chords together and grouped chords that appeared rarely (less than 10 times) under a single label.\n",
    "* The idea was to remove outliers, reduce the output space and improve generalization\n",
    "* As it was indicated that having the amount of output classes be dependent on the input was a bad idea we now use rules independent of the data for grouping and have ~800 classes instead of ~100\n",
    "\n",
    "#### Model\n",
    "* Previously we had a bi-directional LSTM layer in the model architecture as it increased performance. For the sake of being able to compare the results to a simple N-gram model we decided to remove that layer in this iteration.\n",
    "\n",
    "#### Hyperparameters\n",
    "* Given the increased amount of outliers and the removal of the bidirectional layer we expect generalization accuracy to decrease.\n",
    "* To remedy that we used the current model and iterated through different values for a regularization parameter, which we didn't explore previously.\n",
    "* Best scores were obtained with regstrength = 0 however.\n",
    "\n",
    "#### Weighing\n",
    "* Current version, multiply the metrics by the amount of chords in the opus being validated on. ?? Doublecheck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "from chord_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "\n",
    "#Load all data\n",
    "data = pd.read_csv('data/820chords.csv')\n",
    "\n",
    "#Remove redundant attributes. Keep op to split into opuses\n",
    "data = data[['chord', 'op']]\n",
    "\n",
    "#Use dummy variable representation for the chords\n",
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(lstm_x, lstm_y, optimizer, loss, metrics, strength):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences=True, input_shape=(lstm_x.shape[1], lstm_x.shape[2])))\n",
    "    \n",
    "    model.add(Dropout(strength))\n",
    "\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    \n",
    "    model.add(Dropout(strength))\n",
    "    \n",
    "    model.add(Dense(lstm_y.shape[1], activation='softmax'))\n",
    "\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select parameters for the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = 'Adam'\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "epochs = 30\n",
    "verbose = 2\n",
    "seq_length = 10\n",
    "\n",
    "#Save the weights whenever validation accuracy is increased\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'weights.{epoch:02d}-{val_acc:.4f}.hdf5',\n",
    "    monitor='val_acc', \n",
    "    verbose=0,        \n",
    "    save_best_only=False\n",
    ")\n",
    "# Stop the learning process if we havent improved validation accuracy for 10 epochs\n",
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1)\n",
    "\n",
    "#callbacks_list = [checkpoint, earlystop]   \n",
    "callbacks_list = []  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start!\n",
      "\n",
      "Checking dropout strength 0.3\n",
      "\n",
      "Validating on opus 127\n",
      "Train on 25863 samples, validate on 2210 samples\n",
      "Epoch 1/30\n",
      " - 166s - loss: 4.0781 - acc: 0.1209 - val_loss: 4.1679 - val_acc: 0.1253\n",
      "Epoch 2/30\n",
      " - 157s - loss: 3.9687 - acc: 0.1246 - val_loss: 4.1653 - val_acc: 0.1253\n",
      "Epoch 3/30\n",
      " - 183s - loss: 3.9615 - acc: 0.1251 - val_loss: 4.1854 - val_acc: 0.1253\n",
      "Epoch 4/30\n",
      " - 157s - loss: 3.9599 - acc: 0.1261 - val_loss: 4.1749 - val_acc: 0.1253\n",
      "Epoch 5/30\n",
      " - 179s - loss: 3.9583 - acc: 0.1267 - val_loss: 4.1910 - val_acc: 0.1253\n",
      "Epoch 6/30\n",
      " - 173s - loss: 3.9566 - acc: 0.1263 - val_loss: 4.1942 - val_acc: 0.1253\n",
      "Epoch 7/30\n",
      " - 156s - loss: 3.9569 - acc: 0.1262 - val_loss: 4.2119 - val_acc: 0.1253\n",
      "Epoch 8/30\n",
      " - 155s - loss: 3.9537 - acc: 0.1280 - val_loss: 4.1971 - val_acc: 0.1253\n",
      "Epoch 9/30\n",
      " - 155s - loss: 3.9554 - acc: 0.1256 - val_loss: 4.2089 - val_acc: 0.1253\n",
      "Epoch 10/30\n",
      " - 155s - loss: 3.9533 - acc: 0.1271 - val_loss: 4.1935 - val_acc: 0.1253\n",
      "Epoch 11/30\n",
      " - 155s - loss: 3.9544 - acc: 0.1264 - val_loss: 4.2024 - val_acc: 0.1253\n",
      "Epoch 12/30\n",
      " - 155s - loss: 3.9533 - acc: 0.1276 - val_loss: 4.1976 - val_acc: 0.1253\n",
      "Epoch 13/30\n",
      " - 155s - loss: 3.9136 - acc: 0.1337 - val_loss: 4.1626 - val_acc: 0.1258\n",
      "Epoch 14/30\n",
      " - 155s - loss: 3.8357 - acc: 0.1492 - val_loss: 4.1066 - val_acc: 0.1339\n",
      "Epoch 15/30\n",
      " - 155s - loss: 3.7810 - acc: 0.1580 - val_loss: 4.0767 - val_acc: 0.1371\n",
      "Epoch 16/30\n",
      " - 155s - loss: 3.7348 - acc: 0.1677 - val_loss: 4.0318 - val_acc: 0.1511\n",
      "Epoch 17/30\n",
      " - 155s - loss: 3.6765 - acc: 0.1851 - val_loss: 3.9976 - val_acc: 0.1534\n",
      "Epoch 18/30\n",
      " - 156s - loss: 3.6258 - acc: 0.1940 - val_loss: 3.9687 - val_acc: 0.1566\n",
      "Epoch 19/30\n",
      " - 155s - loss: 3.5809 - acc: 0.2038 - val_loss: 3.9821 - val_acc: 0.1525\n",
      "Epoch 20/30\n",
      " - 156s - loss: 3.5388 - acc: 0.2094 - val_loss: 3.9781 - val_acc: 0.1715\n",
      "Epoch 21/30\n",
      " - 155s - loss: 3.4854 - acc: 0.2200 - val_loss: 3.9808 - val_acc: 0.1670\n",
      "Epoch 22/30\n",
      " - 156s - loss: 3.4415 - acc: 0.2242 - val_loss: 3.9745 - val_acc: 0.1661\n",
      "Epoch 23/30\n",
      " - 155s - loss: 3.3940 - acc: 0.2292 - val_loss: 3.9972 - val_acc: 0.1738\n",
      "Epoch 24/30\n",
      " - 160s - loss: 3.3402 - acc: 0.2402 - val_loss: 4.0168 - val_acc: 0.1629\n",
      "Epoch 25/30\n",
      " - 159s - loss: 3.2850 - acc: 0.2492 - val_loss: 4.0318 - val_acc: 0.1652\n",
      "Epoch 26/30\n",
      " - 156s - loss: 3.2307 - acc: 0.2528 - val_loss: 4.0442 - val_acc: 0.1615\n",
      "Epoch 27/30\n",
      " - 160s - loss: 3.1749 - acc: 0.2623 - val_loss: 4.1003 - val_acc: 0.1566\n",
      "Epoch 28/30\n",
      " - 173s - loss: 3.1100 - acc: 0.2750 - val_loss: 4.1146 - val_acc: 0.1656\n",
      "Epoch 29/30\n",
      " - 172s - loss: 3.0437 - acc: 0.2791 - val_loss: 4.1578 - val_acc: 0.1620\n",
      "Epoch 30/30\n",
      " - 156s - loss: 2.9823 - acc: 0.2918 - val_loss: 4.2217 - val_acc: 0.1561\n",
      "\n",
      "Validating on opus 130\n",
      "Train on 25609 samples, validate on 2464 samples\n",
      "Epoch 1/30\n",
      " - 156s - loss: 4.1200 - acc: 0.1162 - val_loss: 3.6970 - val_acc: 0.1530\n",
      "Epoch 2/30\n",
      " - 154s - loss: 4.0064 - acc: 0.1223 - val_loss: 3.7205 - val_acc: 0.1530\n",
      "Epoch 3/30\n",
      " - 153s - loss: 4.0028 - acc: 0.1228 - val_loss: 3.7209 - val_acc: 0.1530\n",
      "Epoch 4/30\n",
      " - 154s - loss: 3.9733 - acc: 0.1304 - val_loss: 3.7080 - val_acc: 0.1485\n",
      "Epoch 5/30\n",
      " - 154s - loss: 3.8765 - acc: 0.1507 - val_loss: 3.6391 - val_acc: 0.1514\n",
      "Epoch 6/30\n",
      " - 154s - loss: 3.7929 - acc: 0.1577 - val_loss: 3.6180 - val_acc: 0.1562\n",
      "Epoch 7/30\n",
      " - 165s - loss: 3.7332 - acc: 0.1625 - val_loss: 3.5986 - val_acc: 0.1619\n",
      "Epoch 8/30\n",
      " - 170s - loss: 3.6743 - acc: 0.1749 - val_loss: 3.5435 - val_acc: 0.1794\n",
      "Epoch 9/30\n",
      " - 164s - loss: 3.6061 - acc: 0.1894 - val_loss: 3.5284 - val_acc: 0.1989\n",
      "Epoch 10/30\n",
      " - 154s - loss: 3.5323 - acc: 0.2066 - val_loss: 3.4931 - val_acc: 0.2114\n",
      "Epoch 11/30\n",
      " - 153s - loss: 3.4659 - acc: 0.2201 - val_loss: 3.4924 - val_acc: 0.2090\n",
      "Epoch 12/30\n",
      " - 154s - loss: 3.4088 - acc: 0.2273 - val_loss: 3.4906 - val_acc: 0.2151\n",
      "Epoch 13/30\n",
      " - 154s - loss: 3.3425 - acc: 0.2396 - val_loss: 3.5231 - val_acc: 0.2147\n",
      "Epoch 14/30\n",
      " - 154s - loss: 3.2818 - acc: 0.2475 - val_loss: 3.5261 - val_acc: 0.2175\n",
      "Epoch 15/30\n",
      " - 154s - loss: 3.2203 - acc: 0.2592 - val_loss: 3.5307 - val_acc: 0.2090\n",
      "Epoch 16/30\n",
      " - 154s - loss: 3.1489 - acc: 0.2691 - val_loss: 3.5372 - val_acc: 0.2139\n",
      "Epoch 17/30\n",
      " - 154s - loss: 3.0875 - acc: 0.2811 - val_loss: 3.5949 - val_acc: 0.2143\n",
      "Epoch 18/30\n",
      " - 154s - loss: 3.0170 - acc: 0.2913 - val_loss: 3.6260 - val_acc: 0.2119\n",
      "Epoch 19/30\n",
      " - 154s - loss: 2.9477 - acc: 0.3026 - val_loss: 3.6369 - val_acc: 0.2171\n",
      "Epoch 20/30\n",
      " - 154s - loss: 2.8736 - acc: 0.3120 - val_loss: 3.6713 - val_acc: 0.2041\n",
      "Epoch 21/30\n",
      " - 154s - loss: 2.7987 - acc: 0.3287 - val_loss: 3.7471 - val_acc: 0.1976\n",
      "Epoch 22/30\n",
      " - 154s - loss: 2.7158 - acc: 0.3444 - val_loss: 3.8327 - val_acc: 0.1920\n",
      "Epoch 23/30\n",
      " - 154s - loss: 2.6484 - acc: 0.3560 - val_loss: 3.8372 - val_acc: 0.2009\n",
      "Epoch 24/30\n",
      " - 154s - loss: 2.5628 - acc: 0.3742 - val_loss: 3.8560 - val_acc: 0.1855\n",
      "Epoch 25/30\n",
      " - 154s - loss: 2.4905 - acc: 0.3876 - val_loss: 3.9877 - val_acc: 0.1814\n",
      "Epoch 26/30\n",
      " - 154s - loss: 2.4055 - acc: 0.4081 - val_loss: 4.0386 - val_acc: 0.1794\n",
      "Epoch 27/30\n",
      " - 154s - loss: 2.3347 - acc: 0.4208 - val_loss: 4.1561 - val_acc: 0.1790\n",
      "Epoch 28/30\n",
      " - 154s - loss: 2.2617 - acc: 0.4328 - val_loss: 4.1720 - val_acc: 0.1794\n",
      "Epoch 29/30\n",
      " - 154s - loss: 2.1797 - acc: 0.4467 - val_loss: 4.2589 - val_acc: 0.1656\n",
      "Epoch 30/30\n",
      " - 154s - loss: 2.1020 - acc: 0.4657 - val_loss: 4.3391 - val_acc: 0.1668\n",
      "\n",
      "Validating on opus 131\n",
      "Train on 25519 samples, validate on 2554 samples\n",
      "Epoch 1/30\n",
      " - 156s - loss: 4.0964 - acc: 0.1216 - val_loss: 3.9868 - val_acc: 0.1316\n",
      "Epoch 2/30\n",
      " - 153s - loss: 3.9876 - acc: 0.1232 - val_loss: 4.0303 - val_acc: 0.1316\n",
      "Epoch 3/30\n",
      " - 153s - loss: 3.9803 - acc: 0.1257 - val_loss: 4.0602 - val_acc: 0.1316\n",
      "Epoch 4/30\n",
      " - 154s - loss: 3.9746 - acc: 0.1268 - val_loss: 4.0599 - val_acc: 0.1316\n",
      "Epoch 5/30\n",
      " - 153s - loss: 3.9733 - acc: 0.1276 - val_loss: 4.0645 - val_acc: 0.1316\n",
      "Epoch 6/30\n",
      " - 153s - loss: 3.9721 - acc: 0.1255 - val_loss: 4.0706 - val_acc: 0.1316\n",
      "Epoch 7/30\n",
      " - 153s - loss: 4.2205 - acc: 0.1250 - val_loss: 4.0786 - val_acc: 0.1316\n",
      "Epoch 8/30\n",
      " - 153s - loss: 3.9739 - acc: 0.1260 - val_loss: 4.0755 - val_acc: 0.1316\n",
      "Epoch 9/30\n",
      " - 156s - loss: 3.9732 - acc: 0.1267 - val_loss: 4.0874 - val_acc: 0.1316\n",
      "Epoch 10/30\n",
      " - 155s - loss: 3.9679 - acc: 0.1274 - val_loss: 4.0726 - val_acc: 0.1316\n",
      "Epoch 11/30\n",
      " - 155s - loss: 3.9686 - acc: 0.1278 - val_loss: 4.0804 - val_acc: 0.1316\n",
      "Epoch 12/30\n",
      " - 155s - loss: 3.9714 - acc: 0.1268 - val_loss: 4.0656 - val_acc: 0.1316\n",
      "Epoch 13/30\n",
      " - 155s - loss: 3.9670 - acc: 0.1263 - val_loss: 4.0725 - val_acc: 0.1316\n",
      "Epoch 14/30\n",
      " - 154s - loss: 3.9672 - acc: 0.1257 - val_loss: 4.0815 - val_acc: 0.1316\n",
      "Epoch 15/30\n",
      " - 154s - loss: 3.9648 - acc: 0.1277 - val_loss: 4.0888 - val_acc: 0.1316\n",
      "Epoch 16/30\n",
      " - 155s - loss: 3.9488 - acc: 0.1303 - val_loss: 4.0334 - val_acc: 0.1276\n",
      "Epoch 17/30\n",
      " - 155s - loss: 3.9179 - acc: 0.1364 - val_loss: 4.0124 - val_acc: 0.1453\n",
      "Epoch 18/30\n",
      " - 155s - loss: 3.8888 - acc: 0.1405 - val_loss: 4.0134 - val_acc: 0.1413\n",
      "Epoch 19/30\n",
      " - 155s - loss: 3.8499 - acc: 0.1467 - val_loss: 3.9722 - val_acc: 0.1519\n",
      "Epoch 20/30\n",
      " - 155s - loss: 3.7970 - acc: 0.1531 - val_loss: 3.9274 - val_acc: 0.1554\n",
      "Epoch 21/30\n",
      " - 155s - loss: 3.7727 - acc: 0.1565 - val_loss: 3.9013 - val_acc: 0.1594\n",
      "Epoch 22/30\n",
      " - 155s - loss: 3.7112 - acc: 0.1649 - val_loss: 3.8908 - val_acc: 0.1609\n",
      "Epoch 23/30\n",
      " - 155s - loss: 3.6564 - acc: 0.1755 - val_loss: 3.8979 - val_acc: 0.1637\n",
      "Epoch 24/30\n",
      " - 155s - loss: 3.6077 - acc: 0.1874 - val_loss: 3.8647 - val_acc: 0.1699\n",
      "Epoch 25/30\n",
      " - 155s - loss: 3.5999 - acc: 0.1883 - val_loss: 3.9179 - val_acc: 0.1680\n",
      "Epoch 26/30\n",
      " - 155s - loss: 3.6274 - acc: 0.1877 - val_loss: 3.9137 - val_acc: 0.1719\n",
      "Epoch 27/30\n",
      " - 155s - loss: 3.5775 - acc: 0.1948 - val_loss: 3.9114 - val_acc: 0.1746\n",
      "Epoch 28/30\n",
      " - 155s - loss: 3.5142 - acc: 0.2010 - val_loss: 3.9039 - val_acc: 0.1750\n",
      "Epoch 29/30\n",
      " - 155s - loss: 3.5074 - acc: 0.2001 - val_loss: 3.9661 - val_acc: 0.1617\n",
      "Epoch 30/30\n",
      " - 154s - loss: 3.6079 - acc: 0.1868 - val_loss: 3.9272 - val_acc: 0.1715\n",
      "\n",
      "Validating on opus 132\n",
      "Train on 25649 samples, validate on 2424 samples\n",
      "Epoch 1/30\n",
      " - 158s - loss: 4.0442 - acc: 0.1235 - val_loss: 4.5648 - val_acc: 0.1139\n",
      "Epoch 2/30\n",
      " - 155s - loss: 3.9308 - acc: 0.1262 - val_loss: 4.6188 - val_acc: 0.1139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      " - 155s - loss: 3.9270 - acc: 0.1269 - val_loss: 4.6513 - val_acc: 0.1139\n",
      "Epoch 4/30\n",
      " - 155s - loss: 3.9212 - acc: 0.1263 - val_loss: 4.6996 - val_acc: 0.1139\n",
      "Epoch 5/30\n",
      " - 155s - loss: 3.9195 - acc: 0.1272 - val_loss: 4.7033 - val_acc: 0.1139\n",
      "Epoch 6/30\n",
      " - 155s - loss: 3.9192 - acc: 0.1275 - val_loss: 4.7295 - val_acc: 0.1139\n",
      "Epoch 7/30\n",
      " - 155s - loss: 3.9184 - acc: 0.1268 - val_loss: 4.7416 - val_acc: 0.1139\n",
      "Epoch 8/30\n",
      " - 155s - loss: 3.9314 - acc: 0.1287 - val_loss: 4.7375 - val_acc: 0.1139\n",
      "Epoch 9/30\n",
      " - 155s - loss: 3.9097 - acc: 0.1284 - val_loss: 4.6849 - val_acc: 0.1139\n",
      "Epoch 10/30\n",
      " - 155s - loss: 3.8817 - acc: 0.1335 - val_loss: 4.6797 - val_acc: 0.1143\n",
      "Epoch 11/30\n",
      " - 155s - loss: 3.8679 - acc: 0.1365 - val_loss: 4.6386 - val_acc: 0.1250\n",
      "Epoch 12/30\n",
      " - 155s - loss: 3.8499 - acc: 0.1398 - val_loss: 4.6077 - val_acc: 0.1328\n",
      "Epoch 13/30\n",
      " - 155s - loss: 3.7994 - acc: 0.1499 - val_loss: 4.5607 - val_acc: 0.1415\n",
      "Epoch 14/30\n",
      " - 155s - loss: 3.7663 - acc: 0.1565 - val_loss: 4.5415 - val_acc: 0.1411\n",
      "Epoch 15/30\n",
      " - 155s - loss: 3.7336 - acc: 0.1605 - val_loss: 4.5126 - val_acc: 0.1473\n",
      "Epoch 16/30\n",
      " - 155s - loss: 3.6967 - acc: 0.1722 - val_loss: 4.4583 - val_acc: 0.1456\n",
      "Epoch 17/30\n",
      " - 155s - loss: 3.6614 - acc: 0.1805 - val_loss: 4.4543 - val_acc: 0.1514\n",
      "Epoch 18/30\n",
      " - 155s - loss: 3.6167 - acc: 0.1892 - val_loss: 4.4276 - val_acc: 0.1390\n",
      "Epoch 19/30\n",
      " - 155s - loss: 3.5740 - acc: 0.1958 - val_loss: 4.3981 - val_acc: 0.1609\n",
      "Epoch 20/30\n",
      " - 155s - loss: 3.5342 - acc: 0.1983 - val_loss: 4.4060 - val_acc: 0.1588\n",
      "Epoch 21/30\n",
      " - 154s - loss: 3.4963 - acc: 0.2072 - val_loss: 4.4043 - val_acc: 0.1564\n",
      "Epoch 22/30\n",
      " - 154s - loss: 3.4604 - acc: 0.2157 - val_loss: 4.3854 - val_acc: 0.1584\n",
      "Epoch 23/30\n",
      " - 155s - loss: 3.4248 - acc: 0.2180 - val_loss: 4.4192 - val_acc: 0.1543\n",
      "Epoch 24/30\n",
      " - 154s - loss: 3.3870 - acc: 0.2256 - val_loss: 4.4447 - val_acc: 0.1543\n",
      "Epoch 25/30\n",
      " - 154s - loss: 3.3502 - acc: 0.2295 - val_loss: 4.4707 - val_acc: 0.1543\n",
      "Epoch 26/30\n",
      " - 154s - loss: 3.3114 - acc: 0.2346 - val_loss: 4.4837 - val_acc: 0.1609\n",
      "Epoch 27/30\n",
      " - 155s - loss: 3.2666 - acc: 0.2399 - val_loss: 4.4971 - val_acc: 0.1646\n",
      "Epoch 28/30\n",
      " - 154s - loss: 3.2190 - acc: 0.2508 - val_loss: 4.5296 - val_acc: 0.1522\n",
      "Epoch 29/30\n",
      " - 154s - loss: 3.1798 - acc: 0.2547 - val_loss: 4.5904 - val_acc: 0.1617\n",
      "Epoch 30/30\n",
      " - 155s - loss: 3.1329 - acc: 0.2588 - val_loss: 4.6152 - val_acc: 0.1531\n",
      "\n",
      "Validating on opus 135\n",
      "Train on 26570 samples, validate on 1503 samples\n",
      "Epoch 1/30\n",
      " - 162s - loss: 4.0786 - acc: 0.1156 - val_loss: 4.2491 - val_acc: 0.1564\n",
      "Epoch 2/30\n",
      " - 158s - loss: 4.0160 - acc: 0.1206 - val_loss: 4.5503 - val_acc: 0.1211\n",
      "Epoch 3/30\n",
      " - 158s - loss: 3.9643 - acc: 0.1259 - val_loss: 4.2739 - val_acc: 0.1570\n",
      "Epoch 4/30\n",
      " - 159s - loss: 3.9291 - acc: 0.1287 - val_loss: 4.2334 - val_acc: 0.1557\n",
      "Epoch 5/30\n",
      " - 159s - loss: 3.9053 - acc: 0.1313 - val_loss: 4.2460 - val_acc: 0.1537\n",
      "Epoch 6/30\n",
      " - 159s - loss: 3.8803 - acc: 0.1373 - val_loss: 4.2514 - val_acc: 0.1557\n",
      "Epoch 7/30\n",
      " - 159s - loss: 3.8045 - acc: 0.1500 - val_loss: 4.2084 - val_acc: 0.1557\n",
      "Epoch 8/30\n",
      " - 159s - loss: 3.7599 - acc: 0.1574 - val_loss: 4.1845 - val_acc: 0.1550\n",
      "Epoch 9/30\n",
      " - 159s - loss: 3.7253 - acc: 0.1631 - val_loss: 4.1554 - val_acc: 0.1590\n",
      "Epoch 10/30\n",
      " - 159s - loss: 3.6825 - acc: 0.1681 - val_loss: 4.1399 - val_acc: 0.1737\n",
      "Epoch 11/30\n",
      " - 159s - loss: 3.6581 - acc: 0.1728 - val_loss: 4.1818 - val_acc: 0.1630\n",
      "Epoch 12/30\n",
      " - 159s - loss: 3.6804 - acc: 0.1684 - val_loss: 4.2282 - val_acc: 0.1697\n",
      "Epoch 13/30\n",
      " - 159s - loss: 3.6778 - acc: 0.1701 - val_loss: 4.2063 - val_acc: 0.1517\n",
      "Epoch 14/30\n",
      " - 159s - loss: 3.6347 - acc: 0.1774 - val_loss: 4.1767 - val_acc: 0.1683\n",
      "Epoch 15/30\n",
      " - 159s - loss: 3.5911 - acc: 0.1831 - val_loss: 4.2183 - val_acc: 0.1464\n",
      "Epoch 16/30\n",
      " - 159s - loss: 3.5613 - acc: 0.1886 - val_loss: 4.2050 - val_acc: 0.1623\n",
      "Epoch 17/30\n",
      " - 181s - loss: 3.5329 - acc: 0.1936 - val_loss: 4.1868 - val_acc: 0.1610\n",
      "Epoch 18/30\n",
      " - 177s - loss: 3.4963 - acc: 0.2013 - val_loss: 4.1888 - val_acc: 0.1557\n",
      "Epoch 19/30\n",
      " - 169s - loss: 3.4562 - acc: 0.2062 - val_loss: 4.1902 - val_acc: 0.1703\n",
      "Epoch 20/30\n",
      " - 159s - loss: 3.4236 - acc: 0.2133 - val_loss: 4.2103 - val_acc: 0.1763\n",
      "Epoch 21/30\n",
      " - 158s - loss: 3.3976 - acc: 0.2172 - val_loss: 4.1825 - val_acc: 0.1683\n",
      "Epoch 22/30\n",
      " - 158s - loss: 3.3486 - acc: 0.2254 - val_loss: 4.1818 - val_acc: 0.1756\n",
      "Epoch 23/30\n",
      " - 158s - loss: 3.2906 - acc: 0.2352 - val_loss: 4.2138 - val_acc: 0.1710\n",
      "Epoch 24/30\n",
      " - 158s - loss: 3.2445 - acc: 0.2384 - val_loss: 4.2343 - val_acc: 0.1683\n",
      "Epoch 25/30\n",
      " - 159s - loss: 3.2060 - acc: 0.2451 - val_loss: 4.2193 - val_acc: 0.1743\n",
      "Epoch 26/30\n",
      " - 159s - loss: 3.1605 - acc: 0.2507 - val_loss: 4.2670 - val_acc: 0.1670\n",
      "Epoch 27/30\n",
      " - 158s - loss: 3.1258 - acc: 0.2545 - val_loss: 4.2881 - val_acc: 0.1670\n",
      "Epoch 28/30\n",
      " - 159s - loss: 3.0822 - acc: 0.2606 - val_loss: 4.3167 - val_acc: 0.1643\n",
      "Epoch 29/30\n",
      " - 158s - loss: 3.0480 - acc: 0.2660 - val_loss: 4.3382 - val_acc: 0.1610\n",
      "Epoch 30/30\n",
      " - 158s - loss: 3.0027 - acc: 0.2766 - val_loss: 4.3555 - val_acc: 0.1717\n",
      "\n",
      "Validating on opus 18\n",
      "Train on 19584 samples, validate on 8489 samples\n",
      "Epoch 1/30\n",
      " - 131s - loss: 4.1913 - acc: 0.1130 - val_loss: 3.8513 - val_acc: 0.1432\n",
      "Epoch 2/30\n",
      " - 127s - loss: 4.0445 - acc: 0.1165 - val_loss: 3.8551 - val_acc: 0.1432\n",
      "Epoch 3/30\n",
      " - 127s - loss: 4.0128 - acc: 0.1231 - val_loss: 3.8326 - val_acc: 0.1471\n",
      "Epoch 4/30\n",
      " - 127s - loss: 3.9759 - acc: 0.1318 - val_loss: 3.8158 - val_acc: 0.1540\n",
      "Epoch 5/30\n",
      " - 128s - loss: 3.9131 - acc: 0.1427 - val_loss: 3.7767 - val_acc: 0.1637\n",
      "Epoch 6/30\n",
      " - 128s - loss: 3.8506 - acc: 0.1539 - val_loss: 3.7496 - val_acc: 0.1654\n",
      "Epoch 7/30\n",
      " - 128s - loss: 3.8175 - acc: 0.1545 - val_loss: 3.7342 - val_acc: 0.1668\n",
      "Epoch 8/30\n",
      " - 128s - loss: 3.7741 - acc: 0.1574 - val_loss: 3.6999 - val_acc: 0.1735\n",
      "Epoch 9/30\n",
      " - 128s - loss: 3.7274 - acc: 0.1628 - val_loss: 3.6608 - val_acc: 0.1877\n",
      "Epoch 10/30\n",
      " - 130s - loss: 3.6803 - acc: 0.1724 - val_loss: 3.6386 - val_acc: 0.1917\n",
      "Epoch 11/30\n",
      " - 129s - loss: 3.6338 - acc: 0.1850 - val_loss: 3.6174 - val_acc: 0.2011\n",
      "Epoch 12/30\n",
      " - 129s - loss: 3.5824 - acc: 0.1943 - val_loss: 3.6093 - val_acc: 0.2040\n",
      "Epoch 13/30\n",
      " - 129s - loss: 3.5323 - acc: 0.2052 - val_loss: 3.6051 - val_acc: 0.2189\n",
      "Epoch 14/30\n",
      " - 129s - loss: 3.4831 - acc: 0.2116 - val_loss: 3.6200 - val_acc: 0.2140\n",
      "Epoch 15/30\n",
      " - 129s - loss: 3.4269 - acc: 0.2169 - val_loss: 3.6068 - val_acc: 0.2217\n",
      "Epoch 16/30\n",
      " - 129s - loss: 3.3690 - acc: 0.2290 - val_loss: 3.6074 - val_acc: 0.2190\n",
      "Epoch 17/30\n",
      " - 129s - loss: 3.3099 - acc: 0.2369 - val_loss: 3.6497 - val_acc: 0.2126\n",
      "Epoch 18/30\n",
      " - 129s - loss: 3.2488 - acc: 0.2403 - val_loss: 3.6636 - val_acc: 0.2149\n",
      "Epoch 19/30\n",
      " - 129s - loss: 3.1876 - acc: 0.2565 - val_loss: 3.6902 - val_acc: 0.2177\n",
      "Epoch 20/30\n",
      " - 129s - loss: 3.1164 - acc: 0.2642 - val_loss: 3.7491 - val_acc: 0.2094\n",
      "Epoch 21/30\n",
      " - 129s - loss: 3.0476 - acc: 0.2745 - val_loss: 3.7977 - val_acc: 0.2099\n",
      "Epoch 22/30\n",
      " - 129s - loss: 2.9748 - acc: 0.2873 - val_loss: 3.8375 - val_acc: 0.2004\n",
      "Epoch 23/30\n",
      " - 129s - loss: 2.8997 - acc: 0.2994 - val_loss: 3.8970 - val_acc: 0.1998\n",
      "Epoch 24/30\n",
      " - 129s - loss: 2.8306 - acc: 0.3113 - val_loss: 3.9043 - val_acc: 0.2017\n",
      "Epoch 25/30\n",
      " - 129s - loss: 2.7508 - acc: 0.3258 - val_loss: 4.0136 - val_acc: 0.1918\n",
      "Epoch 26/30\n",
      " - 129s - loss: 2.6818 - acc: 0.3435 - val_loss: 4.0423 - val_acc: 0.1920\n",
      "Epoch 27/30\n",
      " - 129s - loss: 2.5966 - acc: 0.3556 - val_loss: 4.1007 - val_acc: 0.1917\n",
      "Epoch 28/30\n",
      " - 129s - loss: 2.5141 - acc: 0.3718 - val_loss: 4.2718 - val_acc: 0.1778\n",
      "Epoch 29/30\n",
      " - 129s - loss: 2.4374 - acc: 0.3864 - val_loss: 4.3521 - val_acc: 0.1730\n",
      "Epoch 30/30\n",
      " - 129s - loss: 2.3620 - acc: 0.4001 - val_loss: 4.4328 - val_acc: 0.1713\n",
      "\n",
      "Validating on opus 59\n",
      "Train on 22514 samples, validate on 5559 samples\n",
      "Epoch 1/30\n",
      " - 146s - loss: 4.1015 - acc: 0.1249 - val_loss: 3.9803 - val_acc: 0.1049\n",
      "Epoch 2/30\n",
      " - 142s - loss: 3.9868 - acc: 0.1311 - val_loss: 3.9965 - val_acc: 0.1049\n",
      "Epoch 3/30\n",
      " - 142s - loss: 3.9518 - acc: 0.1334 - val_loss: 3.9647 - val_acc: 0.1049\n",
      "Epoch 4/30\n",
      " - 143s - loss: 3.9241 - acc: 0.1380 - val_loss: 3.9517 - val_acc: 0.1110\n",
      "Epoch 5/30\n",
      " - 142s - loss: 3.8649 - acc: 0.1480 - val_loss: 3.8373 - val_acc: 0.1583\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 142s - loss: 3.7898 - acc: 0.1567 - val_loss: 3.8092 - val_acc: 0.1605\n",
      "Epoch 7/30\n",
      " - 142s - loss: 3.7224 - acc: 0.1632 - val_loss: 3.7749 - val_acc: 0.1669\n",
      "Epoch 8/30\n",
      " - 142s - loss: 3.6567 - acc: 0.1708 - val_loss: 3.7523 - val_acc: 0.1797\n",
      "Epoch 9/30\n",
      " - 142s - loss: 3.5975 - acc: 0.1842 - val_loss: 3.7202 - val_acc: 0.1867\n",
      "Epoch 10/30\n",
      " - 142s - loss: 3.5410 - acc: 0.1974 - val_loss: 3.7124 - val_acc: 0.1997\n",
      "Epoch 11/30\n",
      " - 142s - loss: 3.4675 - acc: 0.2103 - val_loss: 3.7002 - val_acc: 0.1993\n",
      "Epoch 12/30\n",
      " - 142s - loss: 3.4029 - acc: 0.2259 - val_loss: 3.7090 - val_acc: 0.2058\n",
      "Epoch 13/30\n",
      " - 142s - loss: 3.3390 - acc: 0.2335 - val_loss: 3.7048 - val_acc: 0.2157\n",
      "Epoch 14/30\n",
      " - 142s - loss: 3.2688 - acc: 0.2422 - val_loss: 3.7324 - val_acc: 0.2033\n",
      "Epoch 15/30\n",
      " - 141s - loss: 3.1960 - acc: 0.2548 - val_loss: 3.7460 - val_acc: 0.2135\n",
      "Epoch 16/30\n",
      " - 142s - loss: 3.1291 - acc: 0.2665 - val_loss: 3.7960 - val_acc: 0.2085\n",
      "Epoch 17/30\n",
      " - 147s - loss: 3.0575 - acc: 0.2755 - val_loss: 3.7963 - val_acc: 0.2067\n",
      "Epoch 18/30\n",
      " - 158s - loss: 2.9762 - acc: 0.2912 - val_loss: 3.8860 - val_acc: 0.1961\n",
      "Epoch 19/30\n",
      " - 161s - loss: 2.8933 - acc: 0.3073 - val_loss: 3.9206 - val_acc: 0.2018\n",
      "Epoch 20/30\n",
      " - 142s - loss: 2.8126 - acc: 0.3146 - val_loss: 3.9645 - val_acc: 0.1937\n",
      "Epoch 21/30\n",
      " - 142s - loss: 2.7283 - acc: 0.3358 - val_loss: 4.0243 - val_acc: 0.1892\n",
      "Epoch 22/30\n",
      " - 142s - loss: 2.6434 - acc: 0.3536 - val_loss: 4.0989 - val_acc: 0.1900\n",
      "Epoch 23/30\n",
      " - 142s - loss: 2.5561 - acc: 0.3679 - val_loss: 4.1720 - val_acc: 0.1813\n",
      "Epoch 24/30\n",
      " - 142s - loss: 2.4722 - acc: 0.3836 - val_loss: 4.2410 - val_acc: 0.1784\n",
      "Epoch 25/30\n",
      " - 142s - loss: 2.3844 - acc: 0.4010 - val_loss: 4.3676 - val_acc: 0.1709\n",
      "Epoch 26/30\n",
      " - 142s - loss: 2.2948 - acc: 0.4220 - val_loss: 4.4640 - val_acc: 0.1671\n",
      "Epoch 27/30\n",
      " - 142s - loss: 2.2163 - acc: 0.4427 - val_loss: 4.5590 - val_acc: 0.1684\n",
      "Epoch 28/30\n",
      " - 142s - loss: 2.1232 - acc: 0.4582 - val_loss: 4.6700 - val_acc: 0.1617\n",
      "Epoch 29/30\n",
      " - 159s - loss: 2.0470 - acc: 0.4698 - val_loss: 4.7772 - val_acc: 0.1561\n",
      "Epoch 30/30\n",
      " - 158s - loss: 1.9671 - acc: 0.4910 - val_loss: 4.8830 - val_acc: 0.1520\n",
      "\n",
      "Validating on opus 74\n",
      "Train on 26558 samples, validate on 1515 samples\n",
      "Epoch 1/30\n",
      " - 173s - loss: 4.1024 - acc: 0.1192 - val_loss: 3.8086 - val_acc: 0.0950\n",
      "Epoch 2/30\n",
      " - 159s - loss: 3.9962 - acc: 0.1240 - val_loss: 3.8130 - val_acc: 0.1406\n",
      "Epoch 3/30\n",
      " - 159s - loss: 3.9887 - acc: 0.1251 - val_loss: 3.8159 - val_acc: 0.0950\n",
      "Epoch 4/30\n",
      " - 159s - loss: 3.9809 - acc: 0.1265 - val_loss: 3.8072 - val_acc: 0.1406\n",
      "Epoch 5/30\n",
      " - 159s - loss: 3.9470 - acc: 0.1317 - val_loss: 3.7604 - val_acc: 0.1399\n",
      "Epoch 6/30\n",
      " - 160s - loss: 3.8668 - acc: 0.1487 - val_loss: 3.6963 - val_acc: 0.1571\n",
      "Epoch 7/30\n",
      " - 160s - loss: 3.7849 - acc: 0.1578 - val_loss: 3.6913 - val_acc: 0.1650\n",
      "Epoch 8/30\n",
      " - 160s - loss: 3.7233 - acc: 0.1694 - val_loss: 3.6194 - val_acc: 0.1756\n",
      "Epoch 9/30\n",
      " - 160s - loss: 3.6580 - acc: 0.1827 - val_loss: 3.5885 - val_acc: 0.1868\n",
      "Epoch 10/30\n",
      " - 160s - loss: 3.5975 - acc: 0.1912 - val_loss: 3.5536 - val_acc: 0.2092\n",
      "Epoch 11/30\n",
      " - 160s - loss: 3.5367 - acc: 0.2027 - val_loss: 3.5666 - val_acc: 0.2165\n",
      "Epoch 12/30\n",
      " - 159s - loss: 3.4726 - acc: 0.2178 - val_loss: 3.5689 - val_acc: 0.2132\n",
      "Epoch 13/30\n",
      " - 159s - loss: 3.4101 - acc: 0.2257 - val_loss: 3.5585 - val_acc: 0.2165\n",
      "Epoch 14/30\n",
      " - 159s - loss: 3.3489 - acc: 0.2367 - val_loss: 3.5611 - val_acc: 0.2205\n",
      "Epoch 15/30\n",
      " - 159s - loss: 3.2834 - acc: 0.2430 - val_loss: 3.5643 - val_acc: 0.2152\n",
      "Epoch 16/30\n",
      " - 159s - loss: 3.2165 - acc: 0.2521 - val_loss: 3.6001 - val_acc: 0.2257\n",
      "Epoch 17/30\n",
      " - 159s - loss: 3.1426 - acc: 0.2672 - val_loss: 3.6394 - val_acc: 0.2132\n",
      "Epoch 18/30\n",
      " - 159s - loss: 3.0722 - acc: 0.2766 - val_loss: 3.6748 - val_acc: 0.2086\n",
      "Epoch 19/30\n",
      " - 159s - loss: 2.9902 - acc: 0.2912 - val_loss: 3.7388 - val_acc: 0.2000\n",
      "Epoch 20/30\n",
      " - 159s - loss: 2.9169 - acc: 0.3021 - val_loss: 3.7752 - val_acc: 0.2106\n",
      "Epoch 21/30\n",
      " - 159s - loss: 2.8326 - acc: 0.3179 - val_loss: 3.8416 - val_acc: 0.1921\n",
      "Epoch 22/30\n",
      " - 160s - loss: 2.7476 - acc: 0.3297 - val_loss: 3.8929 - val_acc: 0.1855\n",
      "Epoch 23/30\n",
      " - 159s - loss: 2.6631 - acc: 0.3468 - val_loss: 3.9956 - val_acc: 0.1908\n",
      "Epoch 24/30\n",
      " - 159s - loss: 2.5845 - acc: 0.3622 - val_loss: 4.0441 - val_acc: 0.1809\n",
      "Epoch 25/30\n",
      " - 159s - loss: 2.4973 - acc: 0.3763 - val_loss: 4.1036 - val_acc: 0.1703\n",
      "Epoch 26/30\n",
      " - 159s - loss: 2.4155 - acc: 0.3955 - val_loss: 4.2506 - val_acc: 0.1472\n",
      "Epoch 27/30\n",
      " - 159s - loss: 2.3335 - acc: 0.4146 - val_loss: 4.2921 - val_acc: 0.1617\n",
      "Epoch 28/30\n",
      " - 177s - loss: 2.2393 - acc: 0.4294 - val_loss: 4.3918 - val_acc: 0.1531\n",
      "Epoch 29/30\n",
      " - 182s - loss: 2.1637 - acc: 0.4445 - val_loss: 4.5043 - val_acc: 0.1505\n",
      "Epoch 30/30\n",
      " - 160s - loss: 2.0751 - acc: 0.4631 - val_loss: 4.6197 - val_acc: 0.1446\n",
      "\n",
      "Validating on opus 95\n",
      "Train on 26795 samples, validate on 1278 samples\n",
      "Epoch 1/30\n",
      " - 166s - loss: 4.0584 - acc: 0.1244 - val_loss: 4.8027 - val_acc: 0.0806\n",
      "Epoch 2/30\n",
      " - 161s - loss: 3.9517 - acc: 0.1274 - val_loss: 4.8842 - val_acc: 0.0806\n",
      "Epoch 3/30\n",
      " - 161s - loss: 3.9432 - acc: 0.1298 - val_loss: 4.8865 - val_acc: 0.0806\n",
      "Epoch 4/30\n",
      " - 161s - loss: 3.9424 - acc: 0.1292 - val_loss: 4.9306 - val_acc: 0.0806\n",
      "Epoch 5/30\n",
      " - 160s - loss: 3.9464 - acc: 0.1290 - val_loss: 4.9543 - val_acc: 0.0806\n",
      "Epoch 6/30\n",
      " - 160s - loss: 3.9062 - acc: 0.1331 - val_loss: 4.7675 - val_acc: 0.1541\n",
      "Epoch 7/30\n",
      " - 160s - loss: 3.7925 - acc: 0.1536 - val_loss: 4.7129 - val_acc: 0.1581\n",
      "Epoch 8/30\n",
      " - 160s - loss: 3.7219 - acc: 0.1622 - val_loss: 4.6395 - val_acc: 0.1714\n",
      "Epoch 9/30\n",
      " - 161s - loss: 3.6522 - acc: 0.1759 - val_loss: 4.6194 - val_acc: 0.1776\n",
      "Epoch 10/30\n",
      " - 160s - loss: 3.5842 - acc: 0.1926 - val_loss: 4.5740 - val_acc: 0.1714\n",
      "Epoch 11/30\n",
      " - 160s - loss: 3.5215 - acc: 0.2106 - val_loss: 4.5788 - val_acc: 0.1737\n",
      "Epoch 12/30\n",
      " - 160s - loss: 3.4592 - acc: 0.2179 - val_loss: 4.5721 - val_acc: 0.1917\n",
      "Epoch 13/30\n",
      " - 161s - loss: 3.4049 - acc: 0.2288 - val_loss: 4.6097 - val_acc: 0.1886\n",
      "Epoch 14/30\n",
      " - 161s - loss: 3.3411 - acc: 0.2378 - val_loss: 4.6018 - val_acc: 0.1800\n",
      "Epoch 15/30\n",
      " - 161s - loss: 3.2792 - acc: 0.2474 - val_loss: 4.6320 - val_acc: 0.1870\n",
      "Epoch 16/30\n",
      " - 161s - loss: 3.2193 - acc: 0.2579 - val_loss: 4.6588 - val_acc: 0.1737\n",
      "Epoch 17/30\n",
      " - 161s - loss: 3.1482 - acc: 0.2685 - val_loss: 4.7148 - val_acc: 0.1839\n",
      "Epoch 18/30\n",
      " - 160s - loss: 3.0804 - acc: 0.2773 - val_loss: 4.7483 - val_acc: 0.1784\n",
      "Epoch 19/30\n",
      " - 160s - loss: 3.0076 - acc: 0.2935 - val_loss: 4.8273 - val_acc: 0.1753\n",
      "Epoch 20/30\n",
      " - 161s - loss: 2.9386 - acc: 0.3013 - val_loss: 4.8906 - val_acc: 0.1651\n",
      "Epoch 21/30\n",
      " - 161s - loss: 2.8617 - acc: 0.3137 - val_loss: 4.9717 - val_acc: 0.1581\n",
      "Epoch 22/30\n",
      " - 160s - loss: 2.7811 - acc: 0.3318 - val_loss: 5.0763 - val_acc: 0.1635\n",
      "Epoch 23/30\n",
      " - 161s - loss: 2.7056 - acc: 0.3445 - val_loss: 5.1617 - val_acc: 0.1518\n",
      "Epoch 24/30\n",
      " - 161s - loss: 2.6320 - acc: 0.3589 - val_loss: 5.2346 - val_acc: 0.1471\n",
      "Epoch 25/30\n",
      " - 161s - loss: 2.5483 - acc: 0.3742 - val_loss: 5.3673 - val_acc: 0.1408\n",
      "Epoch 26/30\n",
      " - 161s - loss: 2.4688 - acc: 0.3893 - val_loss: 5.3757 - val_acc: 0.1362\n",
      "Epoch 27/30\n",
      " - 161s - loss: 2.3840 - acc: 0.4051 - val_loss: 5.5834 - val_acc: 0.1354\n",
      "Epoch 28/30\n",
      " - 161s - loss: 2.3090 - acc: 0.4200 - val_loss: 5.5867 - val_acc: 0.1354\n",
      "Epoch 29/30\n",
      " - 161s - loss: 2.2217 - acc: 0.4386 - val_loss: 5.6940 - val_acc: 0.1315\n",
      "Epoch 30/30\n",
      " - 161s - loss: 2.1414 - acc: 0.4572 - val_loss: 5.8225 - val_acc: 0.1385\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#define the range of regularization strengths to check\n",
    "dropstrength = [0.3]\n",
    "print(\"Start!\")\n",
    "\n",
    "#Create container for results\n",
    "RESULTS = pd.DataFrame()\n",
    "\n",
    "for strength in dropstrength:\n",
    "    print(\"\\nChecking dropout strength {}\".format(strength))\n",
    "    cv_results = pd.DataFrame()\n",
    "    \n",
    "    #Cross validate on each opus\n",
    "    for opus in data['op'].unique():\n",
    "        print(\"\\nValidating on opus {}\".format(opus))\n",
    "\n",
    "        #Split into training and validation\n",
    "        valid = data[data['op'] == opus]\n",
    "        train = data[data['op'] != opus]\n",
    "\n",
    "        #Drop the opus attribute since it's no longer needed\n",
    "        valid = valid.drop(columns='op')\n",
    "        train = train.drop(columns='op')\n",
    "\n",
    "        #Generate sequences from the data\n",
    "        valid_in, valid_out = generate_sequences(valid, valid, seq_length)\n",
    "        train_in, train_out = generate_sequences(train, train, seq_length)\n",
    "\n",
    "        #Create model\n",
    "        model = lstm(train_in, train_out, optimizer, loss, metrics, strength)\n",
    "\n",
    "        #Train on the folds\n",
    "        model.fit(train_in,\n",
    "                  train_out,\n",
    "                  epochs = epochs,\n",
    "                  verbose = verbose,\n",
    "                  validation_data = (valid_in, valid_out),\n",
    "                  callbacks = callbacks_list)\n",
    "\n",
    "        #Save the history object for the model, appending test opus and regstrength\n",
    "        history = pd.DataFrame(model.history.history)\n",
    "        history.index.name = 'epoch'\n",
    "        history['opus'] = opus\n",
    "        history['reg'] = strength\n",
    "        cv_results = cv_results.append(history)\n",
    "    \n",
    "    RESULTS = RESULTS.append(cv_results)\n",
    "\n",
    "print(\"Done!\")\n",
    "pd.DataFrame.to_csv(RESULTS, './results/dropout_BACKUP.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select which results to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select to load the weighed or the unweighed results\n",
    "RESULTS = pd.read_csv('results/dropout_BACKUP.csv')\n",
    "    \n",
    "#Reindex\n",
    "RESULTS = RESULTS.rename(columns={'reg': 'dropout'})\n",
    "RESULTS = RESULTS.set_index(['dropout','opus'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each regularization value, calculate the average cross-validated score and output it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full table of cross validated scores for each regularization value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>17.666667</td>\n",
       "      <td>3.95759</td>\n",
       "      <td>0.195784</td>\n",
       "      <td>3.369093</td>\n",
       "      <td>0.227901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         epoch  val_loss   val_acc      loss       acc\n",
       "0.3  17.666667   3.95759  0.195784  3.369093  0.227901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>17.666667</td>\n",
       "      <td>3.95759</td>\n",
       "      <td>0.195784</td>\n",
       "      <td>3.369093</td>\n",
       "      <td>0.227901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         epoch  val_loss   val_acc      loss       acc\n",
       "0.3  17.666667   3.95759  0.195784  3.369093  0.227901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AVERAGES = pd.DataFrame()\n",
    "\n",
    "#For each level of regularization\n",
    "for regularization, cvscores in RESULTS.groupby(level=0):\n",
    "    average = pd.DataFrame()\n",
    "    \n",
    "    #Iterate through all folds and extract the highest validation scores\n",
    "    for opus, fold in cvscores.groupby(level=1):\n",
    "\n",
    "        #Retrieve the best score\n",
    "        best = fold[fold['val_acc'] == fold['val_acc'].max()]\n",
    "        average = average.append(best)\n",
    "    \n",
    "    #Make a pretty dataframe of the mean\n",
    "    average = average.describe().loc[['mean']]\n",
    "    average = average.rename(index={'mean': regularization})\n",
    "    \n",
    "    #Take the mean scores for this regularization value and store them in AVERAGE for comparisons\n",
    "    AVERAGES = AVERAGES.append(average)\n",
    "\n",
    "BEST = AVERAGES[AVERAGES['val_acc'] == AVERAGES['val_acc'].max()]\n",
    "\n",
    "print(\"Full table of cross validated scores for each regularization value\")\n",
    "display(AVERAGES)\n",
    "\n",
    "print(\"Best score\")\n",
    "display(BEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chords in each opus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sizes = data.groupby('op')[['chord_#I']].count()\n",
    "sizes = sizes.rename(columns={'chord_#I': 'count'})\n",
    "#sizes = sizes.sort_values(by = 'count', ascending=False)\n",
    "sizes = sizes.append(sizes.describe().loc[['mean']])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.barplot(data=sizes.T)\n",
    "ax.set_title(\"Amount of chords in each opus\")\n",
    "ax.set_ylabel(\"Chords\")\n",
    "ax.set_xlabel(\"Opus\")\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"./figs/chords_per_opus.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation accuracy for each opus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the data from the reg_value that produced the best results\n",
    "best_reg = BEST.index.values[0]\n",
    "df = RESULTS.loc[best_reg]\n",
    "\n",
    "#For each of the nine folds/opuses...\n",
    "scores = pd.DataFrame()\n",
    "for opus, fold in df.groupby(level=0):\n",
    "        \n",
    "        #Drop potential duplicate values\n",
    "        fold = fold.drop_duplicates(subset='val_acc')\n",
    "        \n",
    "        #Retrieve the scores when the val_acc was highest\n",
    "        score = fold[fold['val_acc'] == fold['val_acc'].max()]\n",
    "        \n",
    "        #Store\n",
    "        scores = scores.append(score)\n",
    "\n",
    "#Sort scores by valacc\n",
    "#scores = scores.sort_values(by='val_acc', ascending=False)\n",
    "\n",
    "#Append the average score to the individual scores\n",
    "avg = BEST.rename(index={best_reg: 'mean'})\n",
    "    \n",
    "scores = scores.append(avg)\n",
    "\n",
    "#Plot them\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.barplot(data=scores[['val_acc']].T)\n",
    "#ax.set_title(\"Weighed accuracy on each opus\")\n",
    "ax.set_title(\"Accuracy on each opus\")\n",
    "ax.set_ylabel(\"Accuracy (%)\")\n",
    "ax.set_xlabel(\"Opus\")\n",
    "ax.set_yticklabels(np.around(ax.get_yticks()* 100,2))\n",
    "#fig.savefig(\"./figs/Weighed_NNacc_V.png\")\n",
    "fig.savefig(\"./figs/NNacc_V.png\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,15))\n",
    "sns.barplot(data=scores[['val_acc']].T, orient='horizontal')\n",
    "#ax.set_title(\"Weighed accuracy on each opus\")\n",
    "ax.set_title(\"Accuracy on each opus\")\n",
    "ax.set_xlabel(\"Accuracy (%)\")\n",
    "ax.set_ylabel(\"Opus\")\n",
    "ax.set_xticklabels(np.around(ax.get_xticks()* 100,2))\n",
    "#fig.savefig(\"./figs/Weighed_NNacc_H.png\")\n",
    "fig.savefig(\"./figs/NNacc_H.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout</th>\n",
       "      <th>opus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.3</th>\n",
       "      <th>127</th>\n",
       "      <td>0</td>\n",
       "      <td>4.167877</td>\n",
       "      <td>0.125339</td>\n",
       "      <td>4.078144</td>\n",
       "      <td>0.120945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>4.165304</td>\n",
       "      <td>0.125339</td>\n",
       "      <td>3.968739</td>\n",
       "      <td>0.124618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2</td>\n",
       "      <td>4.185402</td>\n",
       "      <td>0.125339</td>\n",
       "      <td>3.961508</td>\n",
       "      <td>0.125082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>3</td>\n",
       "      <td>4.174947</td>\n",
       "      <td>0.125339</td>\n",
       "      <td>3.959877</td>\n",
       "      <td>0.126087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>4</td>\n",
       "      <td>4.191030</td>\n",
       "      <td>0.125339</td>\n",
       "      <td>3.958276</td>\n",
       "      <td>0.126706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              epoch  val_loss   val_acc      loss       acc\n",
       "dropout opus                                               \n",
       "0.3     127       0  4.167877  0.125339  4.078144  0.120945\n",
       "        127       1  4.165304  0.125339  3.968739  0.124618\n",
       "        127       2  4.185402  0.125339  3.961508  0.125082\n",
       "        127       3  4.174947  0.125339  3.959877  0.126087\n",
       "        127       4  4.191030  0.125339  3.958276  0.126706"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout</th>\n",
       "      <th>opus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.0</th>\n",
       "      <th>127</th>\n",
       "      <td>0</td>\n",
       "      <td>4.1691</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>4.0402</td>\n",
       "      <td>0.1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>4.1654</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>3.9363</td>\n",
       "      <td>0.1284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2</td>\n",
       "      <td>4.1949</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>3.9358</td>\n",
       "      <td>0.1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>3</td>\n",
       "      <td>4.1828</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>3.9349</td>\n",
       "      <td>0.1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>4</td>\n",
       "      <td>4.1958</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>3.9367</td>\n",
       "      <td>0.1279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              epoch  val_loss  val_acc    loss     acc\n",
       "dropout opus                                          \n",
       "0.0     127       0    4.1691   0.1253  4.0402  0.1247\n",
       "        127       1    4.1654   0.1253  3.9363  0.1284\n",
       "        127       2    4.1949   0.1253  3.9358  0.1281\n",
       "        127       3    4.1828   0.1253  3.9349  0.1281\n",
       "        127       4    4.1958   0.1253  3.9367  0.1279"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Restoring unsaved info\n",
    "\n",
    "RESULTS2 = pd.DataFrame()\n",
    "import re\n",
    "f = open(\"savefile.txt\", \"r\")\n",
    "for line in f:\n",
    "\n",
    "    D  = re.search('Checking dropout strength (.*)',line, re.IGNORECASE)\n",
    "    O  = re.search('Validating on opus (\\d*)',line, re.IGNORECASE)\n",
    "    E  = re.search('Epoch (\\d\\d?)/30',line, re.IGNORECASE)\n",
    "    L  = re.search(' - loss: (\\d\\.\\d*) ',line, re.IGNORECASE)\n",
    "    A  = re.search(' - acc: (\\d\\.\\d*) ',line, re.IGNORECASE)\n",
    "    VL = re.search(' - val_loss: (\\d\\.\\d*) ',line, re.IGNORECASE)\n",
    "    VA = re.search(' - val_acc: (\\d\\.\\d*)',line, re.IGNORECASE)\n",
    "\n",
    "    if D:\n",
    "        dropout = float(D.group(1))\n",
    "    if E:\n",
    "        epoch = int(E.group(1)) -1\n",
    "    if O:\n",
    "        opus = int(O.group(1))\n",
    "    if L:\n",
    "        loss = float(L.group(1))\n",
    "    if A:\n",
    "        acc = float(A.group(1))\n",
    "    if VL:\n",
    "        vloss = float(VL.group(1))  \n",
    "    if VA:\n",
    "        vacc = float(VA.group(1))\n",
    "     \n",
    "    if(L):\n",
    "        entry = {'dropout' : [dropout],\n",
    "                 'opus': [opus],\n",
    "                 'epoch': [epoch],\n",
    "                 'val_loss':[vloss],\n",
    "                 'val_acc':[vacc],\n",
    "                 'loss': [loss],\n",
    "                 'acc': [acc]\n",
    "                }\n",
    "        ENTRY = pd.DataFrame(entry)\n",
    "        RESULTS2 = RESULTS2.append(ENTRY)\n",
    "    \n",
    "R = RESULTS2[RESULTS2.dropout != 0.3]\n",
    "R = R.set_index(['dropout', 'opus'])\n",
    "\n",
    "display(RESULTS.head())\n",
    "display(R.head())\n",
    "\n",
    "restore = pd.DataFrame()\n",
    "restore = restore.append(RESULTS)\n",
    "restore = restore.append(R)\n",
    "\n",
    "pd.DataFrame.to_csv(restore, './results/lost_dropout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restored = pd.read_csv('results/dropout_BACKUP.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
