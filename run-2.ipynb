{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To play around\n",
    "You can just head to the section after results and load either the weighed_backup.csv or backup.csv to use the results from the cross validation, no need to run it through again.\n",
    "\n",
    "### Changes from run-1\n",
    "\n",
    "#### Test data\n",
    "* Previously we used cross-validation to select the best model, and tested that model on data (opus 131) that we had kept apart from the beginning.\n",
    "* The scores achieved when predicting on opus 131 were our final results.\n",
    "* This time we train/validate on all data and take the final cross-validation scores as our results.\n",
    "\n",
    "#### Crossvalidation\n",
    "* Previously we simply took all sequences in the train/validate set, shuffled them and trained/validated with a 80/20 split.\n",
    "* This time we instead shuffle the opuses (opi?) before generating the sequences, with the idea that this could hint at how patterns generalize across opuses with. So we basically have leave one (opus) out cross validation.\n",
    "\n",
    "#### Input\n",
    "* Previously we grouped similar chords together and grouped chords that appeared rarely (less than 10 times) under a single label.\n",
    "* The idea was to remove outliers, reduce the output space and improve generalization\n",
    "* As it was indicated that having the amount of output classes be dependent on the input was a bad idea we now use rules independent of the data for grouping and have ~800 classes instead of ~100\n",
    "\n",
    "#### Model\n",
    "* Previously we had a bi-directional LSTM layer in the model architecture as it increased performance. For the sake of being able to compare the results to a simple N-gram model we decided to remove that layer in this iteration.\n",
    "\n",
    "#### Hyperparameters\n",
    "* Given the increased amount of outliers and the removal of the bidirectional layer we expect generalization accuracy to decrease.\n",
    "* To remedy that we used the current model and iterated through different values for a regularization parameter, which we didn't explore previously.\n",
    "* Best scores were obtained with regstrength = 0 however.\n",
    "\n",
    "#### Weighing\n",
    "* Current version, multiply the metrics by the amount of chords in the opus being validated on. ?? Doublecheck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "from chord_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "\n",
    "#Load all data\n",
    "data = pd.read_csv('data/820chords.csv')\n",
    "\n",
    "#Remove redundant attributes. Keep op to split into opuses\n",
    "data = data[['chord', 'op']]\n",
    "\n",
    "#Use dummy variable representation for the chords\n",
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(lstm_x, lstm_y, optimizer, loss, metrics, regstrength):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences=True, input_shape=(lstm_x.shape[1], lstm_x.shape[2]),\\\n",
    "                   kernel_regularizer=regularizers.l2(regstrength)))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(LSTM(64, return_sequences=False,\\\n",
    "              kernel_regularizer=regularizers.l2(regstrength)))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(lstm_y.shape[1], activation='softmax', \\\n",
    "             kernel_regularizer=regularizers.l2(regstrength)))\n",
    "\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select parameters for the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = 'Adam'\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "epochs = 30\n",
    "verbose = 2\n",
    "seq_length = 10\n",
    "\n",
    "#Save the weights whenever validation accuracy is increased\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'weights.{epoch:02d}-{val_acc:.4f}.hdf5',\n",
    "    monitor='val_acc', \n",
    "    verbose=0,        \n",
    "    save_best_only=False\n",
    ")\n",
    "# Stop the learning process if we havent improved validation accuracy for 10 epochs\n",
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1)\n",
    "\n",
    "#callbacks_list = [checkpoint, earlystop]   \n",
    "callbacks_list = [earlystop]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start!\n",
      "\n",
      "Checking regstrength 0\n",
      "\n",
      "Validating on opus 127\n",
      "Train on 25863 samples, validate on 2210 samples\n",
      "Epoch 1/30\n",
      " - 156s - loss: 4.0774 - acc: 0.1196 - val_loss: 4.1609 - val_acc: 0.1253\n",
      "Epoch 2/30\n",
      " - 156s - loss: 3.9651 - acc: 0.1245 - val_loss: 4.1684 - val_acc: 0.1253\n",
      "Epoch 3/30\n",
      " - 153s - loss: 3.9606 - acc: 0.1257 - val_loss: 4.1837 - val_acc: 0.1253\n",
      "Epoch 4/30\n",
      " - 156s - loss: 3.9521 - acc: 0.1265 - val_loss: 4.1703 - val_acc: 0.1253\n",
      "Epoch 5/30\n",
      " - 149s - loss: 3.9519 - acc: 0.1277 - val_loss: 4.1854 - val_acc: 0.1253\n",
      "Epoch 6/30\n",
      " - 149s - loss: 3.9484 - acc: 0.1270 - val_loss: 4.1873 - val_acc: 0.1253\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 130\n",
      "Train on 25609 samples, validate on 2464 samples\n",
      "Epoch 1/30\n",
      " - 150s - loss: 4.1173 - acc: 0.1189 - val_loss: 3.7201 - val_acc: 0.1530\n",
      "Epoch 2/30\n",
      " - 148s - loss: 4.0046 - acc: 0.1227 - val_loss: 3.7432 - val_acc: 0.1530\n",
      "Epoch 3/30\n",
      " - 148s - loss: 3.9974 - acc: 0.1253 - val_loss: 3.7355 - val_acc: 0.1530\n",
      "Epoch 4/30\n",
      " - 148s - loss: 3.9954 - acc: 0.1244 - val_loss: 3.7466 - val_acc: 0.1530\n",
      "Epoch 5/30\n",
      " - 148s - loss: 3.9939 - acc: 0.1251 - val_loss: 3.7472 - val_acc: 0.1530\n",
      "Epoch 6/30\n",
      " - 148s - loss: 4.0158 - acc: 0.1248 - val_loss: 3.7515 - val_acc: 0.1530\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 131\n",
      "Train on 25519 samples, validate on 2554 samples\n",
      "Epoch 1/30\n",
      " - 150s - loss: 4.0920 - acc: 0.1198 - val_loss: 3.9881 - val_acc: 0.1316\n",
      "Epoch 2/30\n",
      " - 148s - loss: 3.9874 - acc: 0.1244 - val_loss: 4.0271 - val_acc: 0.1316\n",
      "Epoch 3/30\n",
      " - 148s - loss: 3.9800 - acc: 0.1263 - val_loss: 4.0413 - val_acc: 0.1316\n",
      "Epoch 4/30\n",
      " - 148s - loss: 3.9721 - acc: 0.1265 - val_loss: 4.0406 - val_acc: 0.1312\n",
      "Epoch 5/30\n",
      " - 148s - loss: 3.9880 - acc: 0.1277 - val_loss: 4.0504 - val_acc: 0.1316\n",
      "Epoch 6/30\n",
      " - 148s - loss: 3.9483 - acc: 0.1310 - val_loss: 4.0344 - val_acc: 0.1359\n",
      "Epoch 7/30\n",
      " - 148s - loss: 3.9266 - acc: 0.1343 - val_loss: 4.0037 - val_acc: 0.1421\n",
      "Epoch 8/30\n",
      " - 148s - loss: 3.9081 - acc: 0.1370 - val_loss: 3.9970 - val_acc: 0.1425\n",
      "Epoch 9/30\n",
      " - 148s - loss: 3.8968 - acc: 0.1385 - val_loss: 4.0121 - val_acc: 0.1390\n",
      "Epoch 10/30\n",
      " - 148s - loss: 3.8797 - acc: 0.1421 - val_loss: 3.9818 - val_acc: 0.1492\n",
      "Epoch 11/30\n",
      " - 148s - loss: 3.8610 - acc: 0.1453 - val_loss: 3.9724 - val_acc: 0.1472\n",
      "Epoch 12/30\n",
      " - 152s - loss: 3.8142 - acc: 0.1528 - val_loss: 3.9271 - val_acc: 0.1527\n",
      "Epoch 13/30\n",
      " - 160s - loss: 3.7736 - acc: 0.1577 - val_loss: 3.8937 - val_acc: 0.1605\n",
      "Epoch 14/30\n",
      " - 153s - loss: 3.7495 - acc: 0.1612 - val_loss: 3.8818 - val_acc: 0.1543\n",
      "Epoch 15/30\n",
      " - 152s - loss: 3.7158 - acc: 0.1669 - val_loss: 3.8805 - val_acc: 0.1590\n",
      "Epoch 16/30\n",
      " - 154s - loss: 3.6641 - acc: 0.1757 - val_loss: 3.8411 - val_acc: 0.1691\n",
      "Epoch 17/30\n",
      " - 148s - loss: 3.6142 - acc: 0.1831 - val_loss: 3.8233 - val_acc: 0.1660\n",
      "Epoch 18/30\n",
      " - 148s - loss: 3.5672 - acc: 0.1933 - val_loss: 3.8429 - val_acc: 0.1754\n",
      "Epoch 19/30\n",
      " - 148s - loss: 3.5262 - acc: 0.1983 - val_loss: 3.8310 - val_acc: 0.1809\n",
      "Epoch 20/30\n",
      " - 148s - loss: 3.4856 - acc: 0.2020 - val_loss: 3.8231 - val_acc: 0.1887\n",
      "Epoch 21/30\n",
      " - 148s - loss: 3.4446 - acc: 0.2106 - val_loss: 3.8526 - val_acc: 0.1922\n",
      "Epoch 22/30\n",
      " - 148s - loss: 3.4045 - acc: 0.2179 - val_loss: 3.8518 - val_acc: 0.1836\n",
      "Epoch 23/30\n",
      " - 148s - loss: 3.3646 - acc: 0.2235 - val_loss: 3.8728 - val_acc: 0.1801\n",
      "Epoch 24/30\n",
      " - 148s - loss: 3.3281 - acc: 0.2298 - val_loss: 3.8507 - val_acc: 0.1864\n",
      "Epoch 25/30\n",
      " - 148s - loss: 3.2787 - acc: 0.2367 - val_loss: 3.9013 - val_acc: 0.1875\n",
      "Epoch 26/30\n",
      " - 148s - loss: 3.2448 - acc: 0.2418 - val_loss: 3.9721 - val_acc: 0.1695\n",
      "Epoch 00026: early stopping\n",
      "\n",
      "Validating on opus 132\n",
      "Train on 25649 samples, validate on 2424 samples\n",
      "Epoch 1/30\n",
      " - 151s - loss: 4.0421 - acc: 0.1201 - val_loss: 4.5479 - val_acc: 0.1139\n",
      "Epoch 2/30\n",
      " - 148s - loss: 3.9305 - acc: 0.1242 - val_loss: 4.6234 - val_acc: 0.1139\n",
      "Epoch 3/30\n",
      " - 148s - loss: 3.9232 - acc: 0.1290 - val_loss: 4.6610 - val_acc: 0.1139\n",
      "Epoch 4/30\n",
      " - 148s - loss: 3.9219 - acc: 0.1289 - val_loss: 4.6784 - val_acc: 0.1139\n",
      "Epoch 5/30\n",
      " - 149s - loss: 3.9211 - acc: 0.1273 - val_loss: 4.7059 - val_acc: 0.1139\n",
      "Epoch 6/30\n",
      " - 149s - loss: 3.9153 - acc: 0.1275 - val_loss: 4.7074 - val_acc: 0.1139\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 135\n",
      "Train on 26570 samples, validate on 1503 samples\n",
      "Epoch 1/30\n",
      " - 156s - loss: 4.0741 - acc: 0.1183 - val_loss: 4.2304 - val_acc: 0.1564\n",
      "Epoch 2/30\n",
      " - 154s - loss: 3.9677 - acc: 0.1227 - val_loss: 4.2794 - val_acc: 0.1564\n",
      "Epoch 3/30\n",
      " - 154s - loss: 3.9592 - acc: 0.1256 - val_loss: 4.2735 - val_acc: 0.1564\n",
      "Epoch 4/30\n",
      " - 154s - loss: 3.9522 - acc: 0.1258 - val_loss: 4.2655 - val_acc: 0.1564\n",
      "Epoch 5/30\n",
      " - 167s - loss: 3.9303 - acc: 0.1304 - val_loss: 4.2328 - val_acc: 0.1570\n",
      "Epoch 6/30\n",
      " - 159s - loss: 3.8512 - acc: 0.1462 - val_loss: 4.1638 - val_acc: 0.1610\n",
      "Epoch 7/30\n",
      " - 168s - loss: 3.7621 - acc: 0.1585 - val_loss: 4.1379 - val_acc: 0.1610\n",
      "Epoch 8/30\n",
      " - 163s - loss: 3.7067 - acc: 0.1619 - val_loss: 4.1199 - val_acc: 0.1590\n",
      "Epoch 9/30\n",
      " - 177s - loss: 3.6358 - acc: 0.1748 - val_loss: 4.1098 - val_acc: 0.1783\n",
      "Epoch 10/30\n",
      " - 173s - loss: 3.5775 - acc: 0.1901 - val_loss: 4.1158 - val_acc: 0.1703\n",
      "Epoch 11/30\n",
      " - 191s - loss: 3.5201 - acc: 0.1985 - val_loss: 4.1139 - val_acc: 0.1657\n",
      "Epoch 12/30\n",
      " - 175s - loss: 3.4678 - acc: 0.2097 - val_loss: 4.1330 - val_acc: 0.1717\n",
      "Epoch 13/30\n",
      " - 157s - loss: 3.4144 - acc: 0.2180 - val_loss: 4.1410 - val_acc: 0.1776\n",
      "Epoch 14/30\n",
      " - 157s - loss: 3.3590 - acc: 0.2274 - val_loss: 4.1508 - val_acc: 0.1823\n",
      "Epoch 15/30\n",
      " - 157s - loss: 3.3125 - acc: 0.2324 - val_loss: 4.1560 - val_acc: 0.1730\n",
      "Epoch 16/30\n",
      " - 157s - loss: 3.2575 - acc: 0.2426 - val_loss: 4.1679 - val_acc: 0.1796\n",
      "Epoch 17/30\n",
      " - 157s - loss: 3.2048 - acc: 0.2482 - val_loss: 4.2341 - val_acc: 0.1710\n",
      "Epoch 18/30\n",
      " - 157s - loss: 3.1437 - acc: 0.2567 - val_loss: 4.2689 - val_acc: 0.1796\n",
      "Epoch 19/30\n",
      " - 157s - loss: 3.0917 - acc: 0.2684 - val_loss: 4.3180 - val_acc: 0.1637\n",
      "Epoch 00019: early stopping\n",
      "\n",
      "Validating on opus 18\n",
      "Train on 19584 samples, validate on 8489 samples\n",
      "Epoch 1/30\n",
      " - 130s - loss: 4.1764 - acc: 0.1164 - val_loss: 3.8380 - val_acc: 0.1432\n",
      "Epoch 2/30\n",
      " - 126s - loss: 4.0356 - acc: 0.1161 - val_loss: 3.8556 - val_acc: 0.1432\n",
      "Epoch 3/30\n",
      " - 126s - loss: 4.0306 - acc: 0.1194 - val_loss: 3.8728 - val_acc: 0.1432\n",
      "Epoch 4/30\n",
      " - 125s - loss: 4.0271 - acc: 0.1217 - val_loss: 3.8724 - val_acc: 0.1432\n",
      "Epoch 5/30\n",
      " - 125s - loss: 4.0229 - acc: 0.1206 - val_loss: 3.8713 - val_acc: 0.1432\n",
      "Epoch 6/30\n",
      " - 125s - loss: 4.0259 - acc: 0.1213 - val_loss: 3.8805 - val_acc: 0.1432\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 59\n",
      "Train on 22514 samples, validate on 5559 samples\n",
      "Epoch 1/30\n",
      " - 143s - loss: 4.1095 - acc: 0.1256 - val_loss: 3.9876 - val_acc: 0.1049\n",
      "Epoch 2/30\n",
      " - 139s - loss: 3.9756 - acc: 0.1326 - val_loss: 4.0011 - val_acc: 0.1049\n",
      "Epoch 3/30\n",
      " - 139s - loss: 3.9686 - acc: 0.1328 - val_loss: 3.9922 - val_acc: 0.1049\n",
      "Epoch 4/30\n",
      " - 139s - loss: 3.9410 - acc: 0.1342 - val_loss: 4.0061 - val_acc: 0.1049\n",
      "Epoch 5/30\n",
      " - 139s - loss: 3.8783 - acc: 0.1443 - val_loss: 3.8876 - val_acc: 0.1414\n",
      "Epoch 6/30\n",
      " - 139s - loss: 3.8069 - acc: 0.1557 - val_loss: 3.8174 - val_acc: 0.1587\n",
      "Epoch 7/30\n",
      " - 139s - loss: 3.7516 - acc: 0.1591 - val_loss: 3.8092 - val_acc: 0.1617\n",
      "Epoch 8/30\n",
      " - 139s - loss: 3.6981 - acc: 0.1708 - val_loss: 3.7980 - val_acc: 0.1707\n",
      "Epoch 9/30\n",
      " - 139s - loss: 3.6451 - acc: 0.1830 - val_loss: 3.7747 - val_acc: 0.1837\n",
      "Epoch 10/30\n",
      " - 139s - loss: 3.5876 - acc: 0.1885 - val_loss: 3.7412 - val_acc: 0.1788\n",
      "Epoch 11/30\n",
      " - 139s - loss: 3.5284 - acc: 0.1995 - val_loss: 3.7466 - val_acc: 0.1876\n",
      "Epoch 12/30\n",
      " - 139s - loss: 3.4740 - acc: 0.2096 - val_loss: 3.7339 - val_acc: 0.1964\n",
      "Epoch 13/30\n",
      " - 139s - loss: 3.4194 - acc: 0.2188 - val_loss: 3.7410 - val_acc: 0.1984\n",
      "Epoch 14/30\n",
      " - 139s - loss: 3.3652 - acc: 0.2255 - val_loss: 3.7593 - val_acc: 0.2015\n",
      "Epoch 15/30\n",
      " - 139s - loss: 3.3092 - acc: 0.2337 - val_loss: 3.7739 - val_acc: 0.2045\n",
      "Epoch 16/30\n",
      " - 140s - loss: 3.2561 - acc: 0.2418 - val_loss: 3.7690 - val_acc: 0.2054\n",
      "Epoch 17/30\n",
      " - 139s - loss: 3.1979 - acc: 0.2530 - val_loss: 3.8071 - val_acc: 0.1946\n",
      "Epoch 18/30\n",
      " - 139s - loss: 3.1386 - acc: 0.2616 - val_loss: 3.8239 - val_acc: 0.1973\n",
      "Epoch 19/30\n",
      " - 139s - loss: 3.0756 - acc: 0.2665 - val_loss: 3.8388 - val_acc: 0.2040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      " - 138s - loss: 3.0211 - acc: 0.2802 - val_loss: 3.8871 - val_acc: 0.2081\n",
      "Epoch 21/30\n",
      " - 139s - loss: 2.9544 - acc: 0.2908 - val_loss: 3.9298 - val_acc: 0.1984\n",
      "Epoch 22/30\n",
      " - 139s - loss: 2.8910 - acc: 0.3009 - val_loss: 3.9916 - val_acc: 0.1923\n",
      "Epoch 23/30\n",
      " - 138s - loss: 2.8284 - acc: 0.3142 - val_loss: 4.0329 - val_acc: 0.1869\n",
      "Epoch 24/30\n",
      " - 138s - loss: 2.7660 - acc: 0.3216 - val_loss: 4.0875 - val_acc: 0.1869\n",
      "Epoch 25/30\n",
      " - 138s - loss: 2.7001 - acc: 0.3317 - val_loss: 4.1294 - val_acc: 0.1838\n",
      "Epoch 00025: early stopping\n",
      "\n",
      "Validating on opus 74\n",
      "Train on 26558 samples, validate on 1515 samples\n",
      "Epoch 1/30\n",
      " - 160s - loss: 4.0954 - acc: 0.1210 - val_loss: 3.8079 - val_acc: 0.1406\n",
      "Epoch 2/30\n",
      " - 156s - loss: 3.9852 - acc: 0.1225 - val_loss: 3.8016 - val_acc: 0.1406\n",
      "Epoch 3/30\n",
      " - 156s - loss: 3.9804 - acc: 0.1257 - val_loss: 3.8097 - val_acc: 0.1406\n",
      "Epoch 4/30\n",
      " - 156s - loss: 3.9787 - acc: 0.1279 - val_loss: 3.8232 - val_acc: 0.1406\n",
      "Epoch 5/30\n",
      " - 155s - loss: 3.9772 - acc: 0.1271 - val_loss: 3.8217 - val_acc: 0.1406\n",
      "Epoch 6/30\n",
      " - 155s - loss: 3.9778 - acc: 0.1264 - val_loss: 3.7964 - val_acc: 0.1406\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 95\n",
      "Train on 26795 samples, validate on 1278 samples\n",
      "Epoch 1/30\n",
      " - 161s - loss: 4.0461 - acc: 0.1243 - val_loss: 4.7996 - val_acc: 0.0806\n",
      "Epoch 2/30\n",
      " - 157s - loss: 3.9448 - acc: 0.1289 - val_loss: 4.8370 - val_acc: 0.0806\n",
      "Epoch 3/30\n",
      " - 157s - loss: 3.9405 - acc: 0.1303 - val_loss: 4.8754 - val_acc: 0.0806\n",
      "Epoch 4/30\n",
      " - 157s - loss: 3.9524 - acc: 0.1295 - val_loss: 4.9409 - val_acc: 0.0806\n",
      "Epoch 5/30\n",
      " - 157s - loss: 3.9570 - acc: 0.1295 - val_loss: 4.8648 - val_acc: 0.0806\n",
      "Epoch 6/30\n",
      " - 157s - loss: 3.9092 - acc: 0.1311 - val_loss: 4.8596 - val_acc: 0.0806\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Checking regstrength 0.001\n",
      "\n",
      "Validating on opus 127\n",
      "Train on 25863 samples, validate on 2210 samples\n",
      "Epoch 1/30\n",
      " - 160s - loss: 4.2232 - acc: 0.1189 - val_loss: 4.2119 - val_acc: 0.1253\n",
      "Epoch 2/30\n",
      " - 155s - loss: 4.0214 - acc: 0.1237 - val_loss: 4.1671 - val_acc: 0.1253\n",
      "Epoch 3/30\n",
      " - 155s - loss: 4.0083 - acc: 0.1267 - val_loss: 4.1770 - val_acc: 0.1253\n",
      "Epoch 4/30\n",
      " - 155s - loss: 3.9845 - acc: 0.1259 - val_loss: 4.1644 - val_acc: 0.1253\n",
      "Epoch 5/30\n",
      " - 191s - loss: 3.9751 - acc: 0.1268 - val_loss: 4.1759 - val_acc: 0.1253\n",
      "Epoch 6/30\n",
      " - 169s - loss: 3.9722 - acc: 0.1267 - val_loss: 4.1611 - val_acc: 0.1253\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 130\n",
      "Train on 25609 samples, validate on 2464 samples\n",
      "Epoch 1/30\n",
      " - 170s - loss: 4.2686 - acc: 0.1183 - val_loss: 3.7804 - val_acc: 0.1530\n",
      "Epoch 2/30\n",
      " - 155s - loss: 4.0653 - acc: 0.1216 - val_loss: 3.7314 - val_acc: 0.1530\n",
      "Epoch 3/30\n",
      " - 155s - loss: 4.0331 - acc: 0.1244 - val_loss: 3.7230 - val_acc: 0.1530\n",
      "Epoch 4/30\n",
      " - 155s - loss: 4.0218 - acc: 0.1241 - val_loss: 3.7321 - val_acc: 0.1530\n",
      "Epoch 5/30\n",
      " - 155s - loss: 4.0131 - acc: 0.1249 - val_loss: 3.7171 - val_acc: 0.1530\n",
      "Epoch 6/30\n",
      " - 155s - loss: 4.0133 - acc: 0.1234 - val_loss: 3.7202 - val_acc: 0.1530\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 131\n",
      "Train on 25519 samples, validate on 2554 samples\n",
      "Epoch 1/30\n",
      " - 161s - loss: 4.2546 - acc: 0.1194 - val_loss: 3.9999 - val_acc: 0.1316\n",
      "Epoch 2/30\n",
      " - 155s - loss: 4.0451 - acc: 0.1245 - val_loss: 3.9848 - val_acc: 0.1316\n",
      "Epoch 3/30\n",
      " - 155s - loss: 4.0113 - acc: 0.1259 - val_loss: 3.9758 - val_acc: 0.1316\n",
      "Epoch 4/30\n",
      " - 155s - loss: 3.9990 - acc: 0.1260 - val_loss: 3.9521 - val_acc: 0.1316\n",
      "Epoch 5/30\n",
      " - 156s - loss: 3.9925 - acc: 0.1272 - val_loss: 3.9485 - val_acc: 0.1316\n",
      "Epoch 6/30\n",
      " - 155s - loss: 4.4027 - acc: 0.1265 - val_loss: 4.0197 - val_acc: 0.1316\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 132\n",
      "Train on 25649 samples, validate on 2424 samples\n",
      "Epoch 1/30\n",
      " - 163s - loss: 4.1972 - acc: 0.1211 - val_loss: 4.4901 - val_acc: 0.1139\n",
      "Epoch 2/30\n",
      " - 158s - loss: 3.9872 - acc: 0.1262 - val_loss: 4.4945 - val_acc: 0.0569\n",
      "Epoch 3/30\n",
      " - 157s - loss: 3.9784 - acc: 0.1273 - val_loss: 4.4857 - val_acc: 0.1139\n",
      "Epoch 4/30\n",
      " - 157s - loss: 3.9437 - acc: 0.1279 - val_loss: 4.4907 - val_acc: 0.1139\n",
      "Epoch 5/30\n",
      " - 157s - loss: 3.9373 - acc: 0.1282 - val_loss: 4.5115 - val_acc: 0.1139\n",
      "Epoch 6/30\n",
      " - 157s - loss: 3.9391 - acc: 0.1289 - val_loss: 4.5073 - val_acc: 0.1139\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 135\n",
      "Train on 26570 samples, validate on 1503 samples\n",
      "Epoch 1/30\n",
      " - 169s - loss: 4.2230 - acc: 0.1170 - val_loss: 4.2178 - val_acc: 0.1564\n",
      "Epoch 2/30\n",
      " - 162s - loss: 4.0234 - acc: 0.1210 - val_loss: 4.1637 - val_acc: 0.1564\n",
      "Epoch 3/30\n",
      " - 162s - loss: 3.9963 - acc: 0.1229 - val_loss: 4.1986 - val_acc: 0.1564\n",
      "Epoch 4/30\n",
      " - 162s - loss: 3.9838 - acc: 0.1229 - val_loss: 4.2110 - val_acc: 0.1564\n",
      "Epoch 5/30\n",
      " - 162s - loss: 3.9804 - acc: 0.1241 - val_loss: 4.1918 - val_acc: 0.1564\n",
      "Epoch 6/30\n",
      " - 162s - loss: 3.9761 - acc: 0.1236 - val_loss: 4.2091 - val_acc: 0.1564\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 18\n",
      "Train on 19584 samples, validate on 8489 samples\n",
      "Epoch 1/30\n",
      " - 139s - loss: 4.3448 - acc: 0.1139 - val_loss: 3.9207 - val_acc: 0.1432\n",
      "Epoch 2/30\n",
      " - 131s - loss: 4.1266 - acc: 0.1173 - val_loss: 3.8895 - val_acc: 0.1432\n",
      "Epoch 3/30\n",
      " - 131s - loss: 4.0869 - acc: 0.1202 - val_loss: 3.8845 - val_acc: 0.1432\n",
      "Epoch 4/30\n",
      " - 131s - loss: 4.0670 - acc: 0.1217 - val_loss: 3.8669 - val_acc: 0.1432\n",
      "Epoch 5/30\n",
      " - 131s - loss: 4.0593 - acc: 0.1215 - val_loss: 3.8459 - val_acc: 0.1432\n",
      "Epoch 6/30\n",
      " - 131s - loss: 4.0519 - acc: 0.1214 - val_loss: 3.8568 - val_acc: 0.1432\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 59\n",
      "Train on 22514 samples, validate on 5559 samples\n",
      "Epoch 1/30\n",
      " - 190s - loss: 4.2717 - acc: 0.1249 - val_loss: 4.0749 - val_acc: 0.1049\n",
      "Epoch 2/30\n",
      " - 157s - loss: 4.0457 - acc: 0.1306 - val_loss: 4.0196 - val_acc: 0.1049\n",
      "Epoch 3/30\n",
      " - 155s - loss: 4.0239 - acc: 0.1334 - val_loss: 4.0104 - val_acc: 0.1049\n",
      "Epoch 4/30\n",
      " - 145s - loss: 4.0094 - acc: 0.1340 - val_loss: 4.0144 - val_acc: 0.1049\n",
      "Epoch 5/30\n",
      " - 145s - loss: 3.9954 - acc: 0.1333 - val_loss: 4.0122 - val_acc: 0.1049\n",
      "Epoch 6/30\n",
      " - 145s - loss: 3.9873 - acc: 0.1332 - val_loss: 4.0087 - val_acc: 0.1049\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 74\n",
      "Train on 26558 samples, validate on 1515 samples\n",
      "Epoch 1/30\n",
      " - 170s - loss: 4.2444 - acc: 0.1211 - val_loss: 3.8714 - val_acc: 0.1406\n",
      "Epoch 2/30\n",
      " - 161s - loss: 4.0456 - acc: 0.1244 - val_loss: 3.8550 - val_acc: 0.1406\n",
      "Epoch 3/30\n",
      " - 161s - loss: 4.0196 - acc: 0.1249 - val_loss: 3.8453 - val_acc: 0.1406\n",
      "Epoch 4/30\n",
      " - 161s - loss: 4.0031 - acc: 0.1260 - val_loss: 3.8154 - val_acc: 0.1406\n",
      "Epoch 5/30\n",
      " - 161s - loss: 3.9981 - acc: 0.1256 - val_loss: 3.8158 - val_acc: 0.1406\n",
      "Epoch 6/30\n",
      " - 161s - loss: 3.9969 - acc: 0.1257 - val_loss: 3.8088 - val_acc: 0.1406\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 95\n",
      "Train on 26795 samples, validate on 1278 samples\n",
      "Epoch 1/30\n",
      " - 170s - loss: 4.2053 - acc: 0.1229 - val_loss: 4.6665 - val_acc: 0.0806\n",
      "Epoch 2/30\n",
      " - 161s - loss: 4.0084 - acc: 0.1265 - val_loss: 4.6690 - val_acc: 0.0806\n",
      "Epoch 3/30\n",
      " - 161s - loss: 3.9782 - acc: 0.1280 - val_loss: 4.6431 - val_acc: 0.0806\n",
      "Epoch 4/30\n",
      " - 161s - loss: 3.9611 - acc: 0.1300 - val_loss: 4.6638 - val_acc: 0.0806\n",
      "Epoch 5/30\n",
      " - 161s - loss: 3.9541 - acc: 0.1285 - val_loss: 4.7268 - val_acc: 0.0806\n",
      "Epoch 6/30\n",
      " - 161s - loss: 3.9522 - acc: 0.1292 - val_loss: 4.7021 - val_acc: 0.0806\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Checking regstrength 0.005\n",
      "\n",
      "Validating on opus 127\n",
      "Train on 25863 samples, validate on 2210 samples\n",
      "Epoch 1/30\n",
      " - 166s - loss: 4.4022 - acc: 0.1209 - val_loss: 4.2167 - val_acc: 0.1253\n",
      "Epoch 2/30\n",
      " - 156s - loss: 4.0397 - acc: 0.1248 - val_loss: 4.2184 - val_acc: 0.1253\n",
      "Epoch 3/30\n",
      " - 156s - loss: 4.0307 - acc: 0.1270 - val_loss: 4.2260 - val_acc: 0.1253\n",
      "Epoch 4/30\n",
      " - 156s - loss: 4.0245 - acc: 0.1266 - val_loss: 4.2118 - val_acc: 0.1253\n",
      "Epoch 5/30\n",
      " - 157s - loss: 4.0224 - acc: 0.1273 - val_loss: 4.2222 - val_acc: 0.1253\n",
      "Epoch 6/30\n",
      " - 156s - loss: 4.0203 - acc: 0.1259 - val_loss: 4.2110 - val_acc: 0.1253\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 130\n",
      "Train on 25609 samples, validate on 2464 samples\n",
      "Epoch 1/30\n",
      " - 166s - loss: 4.4464 - acc: 0.1179 - val_loss: 3.7797 - val_acc: 0.1530\n",
      "Epoch 2/30\n",
      " - 156s - loss: 4.0790 - acc: 0.1230 - val_loss: 3.7896 - val_acc: 0.1530\n",
      "Epoch 3/30\n",
      " - 156s - loss: 4.0707 - acc: 0.1224 - val_loss: 3.7686 - val_acc: 0.1530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      " - 156s - loss: 4.0636 - acc: 0.1253 - val_loss: 3.7646 - val_acc: 0.0954\n",
      "Epoch 5/30\n",
      " - 156s - loss: 4.0624 - acc: 0.1232 - val_loss: 3.7766 - val_acc: 0.1530\n",
      "Epoch 6/30\n",
      " - 156s - loss: 4.0603 - acc: 0.1242 - val_loss: 3.7966 - val_acc: 0.0954\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 131\n",
      "Train on 25519 samples, validate on 2554 samples\n",
      "Epoch 1/30\n",
      " - 165s - loss: 4.4184 - acc: 0.1192 - val_loss: 4.0115 - val_acc: 0.1316\n",
      "Epoch 2/30\n",
      " - 155s - loss: 4.0570 - acc: 0.1241 - val_loss: 3.9921 - val_acc: 0.1316\n",
      "Epoch 3/30\n",
      " - 155s - loss: 4.0466 - acc: 0.1261 - val_loss: 4.0185 - val_acc: 0.1316\n",
      "Epoch 4/30\n",
      " - 155s - loss: 4.0450 - acc: 0.1265 - val_loss: 4.0183 - val_acc: 0.1316\n",
      "Epoch 5/30\n",
      " - 155s - loss: 4.0389 - acc: 0.1262 - val_loss: 4.0177 - val_acc: 0.1316\n",
      "Epoch 6/30\n",
      " - 155s - loss: 4.0387 - acc: 0.1270 - val_loss: 4.0131 - val_acc: 0.1316\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 132\n",
      "Train on 25649 samples, validate on 2424 samples\n",
      "Epoch 1/30\n",
      " - 167s - loss: 4.3735 - acc: 0.1216 - val_loss: 4.5159 - val_acc: 0.1139\n",
      "Epoch 2/30\n",
      " - 156s - loss: 4.0080 - acc: 0.1269 - val_loss: 4.5152 - val_acc: 0.1139\n",
      "Epoch 3/30\n",
      " - 156s - loss: 3.9981 - acc: 0.1274 - val_loss: 4.5176 - val_acc: 0.1139\n",
      "Epoch 4/30\n",
      " - 156s - loss: 3.9938 - acc: 0.1249 - val_loss: 4.5288 - val_acc: 0.1139\n",
      "Epoch 5/30\n",
      " - 156s - loss: 3.9886 - acc: 0.1283 - val_loss: 4.5560 - val_acc: 0.1139\n",
      "Epoch 6/30\n",
      " - 156s - loss: 3.9831 - acc: 0.1275 - val_loss: 4.5530 - val_acc: 0.1139\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 135\n",
      "Train on 26570 samples, validate on 1503 samples\n",
      "Epoch 1/30\n",
      " - 171s - loss: 4.4023 - acc: 0.1203 - val_loss: 4.1988 - val_acc: 0.1564\n",
      "Epoch 2/30\n",
      " - 160s - loss: 4.0425 - acc: 0.1237 - val_loss: 4.2023 - val_acc: 0.1564\n",
      "Epoch 3/30\n",
      " - 160s - loss: 4.0346 - acc: 0.1237 - val_loss: 4.2288 - val_acc: 0.1564\n",
      "Epoch 4/30\n",
      " - 160s - loss: 4.0298 - acc: 0.1240 - val_loss: 4.2393 - val_acc: 0.1564\n",
      "Epoch 5/30\n",
      " - 160s - loss: 4.0240 - acc: 0.1241 - val_loss: 4.2582 - val_acc: 0.1564\n",
      "Epoch 6/30\n",
      " - 160s - loss: 4.0219 - acc: 0.1251 - val_loss: 4.2328 - val_acc: 0.1564\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 18\n",
      "Train on 19584 samples, validate on 8489 samples\n",
      "Epoch 1/30\n",
      " - 141s - loss: 4.5807 - acc: 0.1142 - val_loss: 3.9404 - val_acc: 0.1432\n",
      "Epoch 2/30\n",
      " - 129s - loss: 4.1237 - acc: 0.1181 - val_loss: 3.9158 - val_acc: 0.1432\n",
      "Epoch 3/30\n",
      " - 129s - loss: 4.1070 - acc: 0.1176 - val_loss: 3.9024 - val_acc: 0.1432\n",
      "Epoch 4/30\n",
      " - 129s - loss: 4.1026 - acc: 0.1192 - val_loss: 3.9195 - val_acc: 0.1432\n",
      "Epoch 5/30\n",
      " - 129s - loss: 4.0984 - acc: 0.1206 - val_loss: 3.9096 - val_acc: 0.1432\n",
      "Epoch 6/30\n",
      " - 129s - loss: 4.0954 - acc: 0.1218 - val_loss: 3.9020 - val_acc: 0.1432\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 59\n",
      "Train on 22514 samples, validate on 5559 samples\n",
      "Epoch 1/30\n",
      " - 155s - loss: 4.4659 - acc: 0.1257 - val_loss: 4.0781 - val_acc: 0.1049\n",
      "Epoch 2/30\n",
      " - 142s - loss: 4.0544 - acc: 0.1310 - val_loss: 4.0618 - val_acc: 0.1087\n",
      "Epoch 3/30\n",
      " - 142s - loss: 4.0421 - acc: 0.1341 - val_loss: 4.0583 - val_acc: 0.1049\n",
      "Epoch 4/30\n",
      " - 142s - loss: 4.0367 - acc: 0.1340 - val_loss: 4.0650 - val_acc: 0.1049\n",
      "Epoch 5/30\n",
      " - 142s - loss: 4.0359 - acc: 0.1330 - val_loss: 4.0696 - val_acc: 0.1049\n",
      "Epoch 6/30\n",
      " - 142s - loss: 4.0301 - acc: 0.1338 - val_loss: 4.0435 - val_acc: 0.1049\n",
      "Epoch 7/30\n",
      " - 142s - loss: 4.0269 - acc: 0.1346 - val_loss: 4.0563 - val_acc: 0.1049\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "Validating on opus 74\n",
      "Train on 26558 samples, validate on 1515 samples\n",
      "Epoch 1/30\n",
      " - 174s - loss: 4.4181 - acc: 0.1218 - val_loss: 3.8822 - val_acc: 0.1406\n",
      "Epoch 2/30\n",
      " - 161s - loss: 4.0611 - acc: 0.1258 - val_loss: 3.8786 - val_acc: 0.1406\n",
      "Epoch 3/30\n",
      " - 161s - loss: 4.0544 - acc: 0.1261 - val_loss: 3.8918 - val_acc: 0.1406\n",
      "Epoch 4/30\n",
      " - 161s - loss: 4.0492 - acc: 0.1271 - val_loss: 3.8803 - val_acc: 0.1406\n",
      "Epoch 5/30\n",
      " - 161s - loss: 4.0470 - acc: 0.1260 - val_loss: 3.8638 - val_acc: 0.1406\n",
      "Epoch 6/30\n",
      " - 161s - loss: 4.0436 - acc: 0.1264 - val_loss: 3.8804 - val_acc: 0.1406\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 95\n",
      "Train on 26795 samples, validate on 1278 samples\n",
      "Epoch 1/30\n",
      " - 176s - loss: 4.3759 - acc: 0.1253 - val_loss: 4.6821 - val_acc: 0.0806\n",
      "Epoch 2/30\n",
      " - 162s - loss: 4.0211 - acc: 0.1274 - val_loss: 4.6868 - val_acc: 0.0806\n",
      "Epoch 3/30\n",
      " - 162s - loss: 4.0120 - acc: 0.1288 - val_loss: 4.6962 - val_acc: 0.0806\n",
      "Epoch 4/30\n",
      " - 162s - loss: 4.0076 - acc: 0.1294 - val_loss: 4.7066 - val_acc: 0.0806\n",
      "Epoch 5/30\n",
      " - 162s - loss: 4.0039 - acc: 0.1286 - val_loss: 4.7148 - val_acc: 0.0806\n",
      "Epoch 6/30\n",
      " - 162s - loss: 4.0004 - acc: 0.1292 - val_loss: 4.7496 - val_acc: 0.0806\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Checking regstrength 0.01\n",
      "\n",
      "Validating on opus 127\n",
      "Train on 25863 samples, validate on 2210 samples\n",
      "Epoch 1/30\n",
      " - 173s - loss: 4.5892 - acc: 0.1221 - val_loss: 4.2665 - val_acc: 0.1253\n",
      "Epoch 2/30\n",
      " - 158s - loss: 4.0925 - acc: 0.1261 - val_loss: 4.2746 - val_acc: 0.1253\n",
      "Epoch 3/30\n",
      " - 165s - loss: 4.0805 - acc: 0.1267 - val_loss: 4.2573 - val_acc: 0.1253\n",
      "Epoch 4/30\n",
      " - 159s - loss: 4.0721 - acc: 0.1266 - val_loss: 4.2605 - val_acc: 0.1253\n",
      "Epoch 5/30\n",
      " - 159s - loss: 4.0654 - acc: 0.1274 - val_loss: 4.2644 - val_acc: 0.1253\n",
      "Epoch 6/30\n",
      " - 159s - loss: 4.0604 - acc: 0.1264 - val_loss: 4.2510 - val_acc: 0.1253\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 130\n",
      "Train on 25609 samples, validate on 2464 samples\n",
      "Epoch 1/30\n",
      " - 173s - loss: 4.6450 - acc: 0.1204 - val_loss: 3.8357 - val_acc: 0.1530\n",
      "Epoch 2/30\n",
      " - 158s - loss: 4.1325 - acc: 0.1252 - val_loss: 3.8600 - val_acc: 0.0954\n",
      "Epoch 3/30\n",
      " - 158s - loss: 4.1225 - acc: 0.1243 - val_loss: 3.8222 - val_acc: 0.1530\n",
      "Epoch 4/30\n",
      " - 158s - loss: 4.1153 - acc: 0.1236 - val_loss: 3.8407 - val_acc: 0.1530\n",
      "Epoch 5/30\n",
      " - 157s - loss: 4.1044 - acc: 0.1249 - val_loss: 3.8191 - val_acc: 0.0954\n",
      "Epoch 6/30\n",
      " - 158s - loss: 4.1002 - acc: 0.1256 - val_loss: 3.8452 - val_acc: 0.1530\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 131\n",
      "Train on 25519 samples, validate on 2554 samples\n",
      "Epoch 1/30\n",
      " - 173s - loss: 4.6289 - acc: 0.1234 - val_loss: 4.0325 - val_acc: 0.1316\n",
      "Epoch 2/30\n",
      " - 157s - loss: 4.1114 - acc: 0.1285 - val_loss: 4.0415 - val_acc: 0.1316\n",
      "Epoch 3/30\n",
      " - 157s - loss: 4.0996 - acc: 0.1249 - val_loss: 4.0180 - val_acc: 0.1316\n",
      "Epoch 4/30\n",
      " - 157s - loss: 4.0889 - acc: 0.1272 - val_loss: 4.0573 - val_acc: 0.1316\n",
      "Epoch 5/30\n",
      " - 157s - loss: 4.0850 - acc: 0.1259 - val_loss: 4.0461 - val_acc: 0.1316\n",
      "Epoch 6/30\n",
      " - 157s - loss: 4.0747 - acc: 0.1279 - val_loss: 4.0467 - val_acc: 0.1316\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 132\n",
      "Train on 25649 samples, validate on 2424 samples\n",
      "Epoch 1/30\n",
      " - 175s - loss: 4.5730 - acc: 0.1252 - val_loss: 4.5514 - val_acc: 0.1139\n",
      "Epoch 2/30\n",
      " - 158s - loss: 4.0609 - acc: 0.1283 - val_loss: 4.5625 - val_acc: 0.1139\n",
      "Epoch 3/30\n",
      " - 158s - loss: 4.0481 - acc: 0.1276 - val_loss: 4.5477 - val_acc: 0.1139\n",
      "Epoch 4/30\n",
      " - 158s - loss: 4.0353 - acc: 0.1264 - val_loss: 4.5715 - val_acc: 0.1139\n",
      "Epoch 5/30\n",
      " - 158s - loss: 4.0280 - acc: 0.1289 - val_loss: 4.5860 - val_acc: 0.1139\n",
      "Epoch 6/30\n",
      " - 158s - loss: 4.0187 - acc: 0.1267 - val_loss: 4.5904 - val_acc: 0.1139\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 135\n",
      "Train on 26570 samples, validate on 1503 samples\n",
      "Epoch 1/30\n",
      " - 179s - loss: 4.5942 - acc: 0.1219 - val_loss: 4.2765 - val_acc: 0.1564\n",
      "Epoch 2/30\n",
      " - 162s - loss: 4.0950 - acc: 0.1254 - val_loss: 4.2584 - val_acc: 0.1564\n",
      "Epoch 3/30\n",
      " - 162s - loss: 4.0849 - acc: 0.1253 - val_loss: 4.2781 - val_acc: 0.1564\n",
      "Epoch 4/30\n",
      " - 162s - loss: 4.0768 - acc: 0.1247 - val_loss: 4.2854 - val_acc: 0.1564\n",
      "Epoch 5/30\n",
      " - 162s - loss: 4.0679 - acc: 0.1261 - val_loss: 4.2803 - val_acc: 0.1564\n",
      "Epoch 6/30\n",
      " - 162s - loss: 4.0602 - acc: 0.1259 - val_loss: 4.2809 - val_acc: 0.1564\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 18\n",
      "Train on 19584 samples, validate on 8489 samples\n",
      "Epoch 1/30\n",
      " - 148s - loss: 4.8402 - acc: 0.1141 - val_loss: 3.9817 - val_acc: 0.1432\n",
      "Epoch 2/30\n",
      " - 129s - loss: 4.1722 - acc: 0.1205 - val_loss: 3.9813 - val_acc: 0.1432\n",
      "Epoch 3/30\n",
      " - 129s - loss: 4.1602 - acc: 0.1209 - val_loss: 3.9563 - val_acc: 0.1432\n",
      "Epoch 4/30\n",
      " - 130s - loss: 4.1526 - acc: 0.1192 - val_loss: 3.9475 - val_acc: 0.1432\n",
      "Epoch 5/30\n",
      " - 129s - loss: 4.1447 - acc: 0.1216 - val_loss: 3.9555 - val_acc: 0.1432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      " - 130s - loss: 4.1393 - acc: 0.1217 - val_loss: 3.9602 - val_acc: 0.1432\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 59\n",
      "Train on 22514 samples, validate on 5559 samples\n",
      "Epoch 1/30\n",
      " - 161s - loss: 4.6785 - acc: 0.1312 - val_loss: 4.1330 - val_acc: 0.1049\n",
      "Epoch 2/30\n",
      " - 142s - loss: 4.1045 - acc: 0.1331 - val_loss: 4.1173 - val_acc: 0.1049\n",
      "Epoch 3/30\n",
      " - 142s - loss: 4.0955 - acc: 0.1343 - val_loss: 4.1117 - val_acc: 0.1049\n",
      "Epoch 4/30\n",
      " - 142s - loss: 4.0844 - acc: 0.1339 - val_loss: 4.1087 - val_acc: 0.1049\n",
      "Epoch 5/30\n",
      " - 142s - loss: 4.0765 - acc: 0.1343 - val_loss: 4.1149 - val_acc: 0.1049\n",
      "Epoch 6/30\n",
      " - 142s - loss: 4.0707 - acc: 0.1339 - val_loss: 4.1230 - val_acc: 0.1049\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 74\n",
      "Train on 26558 samples, validate on 1515 samples\n",
      "Epoch 1/30\n",
      " - 182s - loss: 4.6054 - acc: 0.1239 - val_loss: 3.9302 - val_acc: 0.1406\n",
      "Epoch 2/30\n",
      " - 161s - loss: 4.1135 - acc: 0.1249 - val_loss: 3.9386 - val_acc: 0.1406\n",
      "Epoch 3/30\n",
      " - 161s - loss: 4.1049 - acc: 0.1270 - val_loss: 3.9439 - val_acc: 0.1406\n",
      "Epoch 4/30\n",
      " - 161s - loss: 4.0953 - acc: 0.1253 - val_loss: 3.9189 - val_acc: 0.1406\n",
      "Epoch 5/30\n",
      " - 161s - loss: 4.0874 - acc: 0.1270 - val_loss: 3.9222 - val_acc: 0.1406\n",
      "Epoch 6/30\n",
      " - 161s - loss: 4.0842 - acc: 0.1275 - val_loss: 3.9187 - val_acc: 0.1406\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 95\n",
      "Train on 26795 samples, validate on 1278 samples\n",
      "Epoch 1/30\n",
      " - 183s - loss: 4.5647 - acc: 0.1223 - val_loss: 4.7018 - val_acc: 0.0806\n",
      "Epoch 2/30\n",
      " - 162s - loss: 4.0755 - acc: 0.1289 - val_loss: 4.7263 - val_acc: 0.0806\n",
      "Epoch 3/30\n",
      " - 162s - loss: 4.0631 - acc: 0.1304 - val_loss: 4.7165 - val_acc: 0.0806\n",
      "Epoch 4/30\n",
      " - 162s - loss: 4.0540 - acc: 0.1297 - val_loss: 4.7441 - val_acc: 0.0790\n",
      "Epoch 5/30\n",
      " - 162s - loss: 4.0460 - acc: 0.1282 - val_loss: 4.7481 - val_acc: 0.0806\n",
      "Epoch 6/30\n",
      " - 163s - loss: 4.0411 - acc: 0.1281 - val_loss: 4.7504 - val_acc: 0.0806\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Checking regstrength 0.05\n",
      "\n",
      "Validating on opus 127\n",
      "Train on 25863 samples, validate on 2210 samples\n",
      "Epoch 1/30\n",
      " - 180s - loss: 6.1063 - acc: 0.1260 - val_loss: 4.5419 - val_acc: 0.1253\n",
      "Epoch 2/30\n",
      " - 158s - loss: 4.3315 - acc: 0.1277 - val_loss: 4.5096 - val_acc: 0.1253\n",
      "Epoch 3/30\n",
      " - 158s - loss: 4.2836 - acc: 0.1289 - val_loss: 4.4419 - val_acc: 0.1253\n",
      "Epoch 4/30\n",
      " - 158s - loss: 4.2400 - acc: 0.1268 - val_loss: 4.4323 - val_acc: 0.1253\n",
      "Epoch 5/30\n",
      " - 158s - loss: 4.2052 - acc: 0.1292 - val_loss: 4.3978 - val_acc: 0.1253\n",
      "Epoch 6/30\n",
      " - 158s - loss: 4.1752 - acc: 0.1281 - val_loss: 4.3906 - val_acc: 0.1253\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 130\n",
      "Train on 25609 samples, validate on 2464 samples\n",
      "Epoch 1/30\n",
      " - 180s - loss: 6.1561 - acc: 0.1218 - val_loss: 4.1103 - val_acc: 0.1530\n",
      "Epoch 2/30\n",
      " - 158s - loss: 4.3755 - acc: 0.1251 - val_loss: 4.0653 - val_acc: 0.1530\n",
      "Epoch 3/30\n",
      " - 158s - loss: 4.3228 - acc: 0.1257 - val_loss: 4.0644 - val_acc: 0.1530\n",
      "Epoch 4/30\n",
      " - 157s - loss: 4.2829 - acc: 0.1244 - val_loss: 3.9858 - val_acc: 0.1530\n",
      "Epoch 5/30\n",
      " - 158s - loss: 4.2446 - acc: 0.1257 - val_loss: 3.9760 - val_acc: 0.1530\n",
      "Epoch 6/30\n",
      " - 157s - loss: 4.2150 - acc: 0.1248 - val_loss: 3.9550 - val_acc: 0.1530\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 131\n",
      "Train on 25519 samples, validate on 2554 samples\n",
      "Epoch 1/30\n",
      " - 179s - loss: 6.1510 - acc: 0.1257 - val_loss: 4.2892 - val_acc: 0.1316\n",
      "Epoch 2/30\n",
      " - 156s - loss: 4.3544 - acc: 0.1265 - val_loss: 4.2589 - val_acc: 0.1316\n",
      "Epoch 3/30\n",
      " - 156s - loss: 4.3008 - acc: 0.1277 - val_loss: 4.2290 - val_acc: 0.1316\n",
      "Epoch 4/30\n",
      " - 156s - loss: 4.2590 - acc: 0.1279 - val_loss: 4.1914 - val_acc: 0.1316\n",
      "Epoch 5/30\n",
      " - 156s - loss: 4.2229 - acc: 0.1276 - val_loss: 4.1851 - val_acc: 0.1316\n",
      "Epoch 6/30\n",
      " - 156s - loss: 4.1925 - acc: 0.1265 - val_loss: 4.1637 - val_acc: 0.1316\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 132\n",
      "Train on 25649 samples, validate on 2424 samples\n",
      "Epoch 1/30\n",
      " - 180s - loss: 6.1115 - acc: 0.1257 - val_loss: 4.7780 - val_acc: 0.1139\n",
      "Epoch 2/30\n",
      " - 157s - loss: 4.3018 - acc: 0.1294 - val_loss: 4.7483 - val_acc: 0.1139\n",
      "Epoch 3/30\n",
      " - 156s - loss: 4.2478 - acc: 0.1283 - val_loss: 4.7071 - val_acc: 0.1139\n",
      "Epoch 4/30\n",
      " - 156s - loss: 4.2037 - acc: 0.1293 - val_loss: 4.6899 - val_acc: 0.1139\n",
      "Epoch 5/30\n",
      " - 156s - loss: 4.1671 - acc: 0.1283 - val_loss: 4.6826 - val_acc: 0.1139\n",
      "Epoch 6/30\n",
      " - 156s - loss: 4.1360 - acc: 0.1298 - val_loss: 4.6762 - val_acc: 0.1139\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 135\n",
      "Train on 26570 samples, validate on 1503 samples\n",
      "Epoch 1/30\n",
      " - 185s - loss: 6.0580 - acc: 0.1241 - val_loss: 4.4901 - val_acc: 0.1564\n",
      "Epoch 2/30\n",
      " - 160s - loss: 4.3366 - acc: 0.1268 - val_loss: 4.4406 - val_acc: 0.1564\n",
      "Epoch 3/30\n",
      " - 160s - loss: 4.2856 - acc: 0.1251 - val_loss: 4.4478 - val_acc: 0.1564\n",
      "Epoch 4/30\n",
      " - 160s - loss: 4.2406 - acc: 0.1248 - val_loss: 4.4000 - val_acc: 0.1564\n",
      "Epoch 5/30\n",
      " - 160s - loss: 4.2064 - acc: 0.1249 - val_loss: 4.3939 - val_acc: 0.1564\n",
      "Epoch 6/30\n",
      " - 160s - loss: 4.1729 - acc: 0.1244 - val_loss: 4.3721 - val_acc: 0.1564\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 18\n",
      "Train on 19584 samples, validate on 8489 samples\n",
      "Epoch 1/30\n",
      " - 158s - loss: 6.7355 - acc: 0.1216 - val_loss: 4.2572 - val_acc: 0.1432\n",
      "Epoch 2/30\n",
      " - 130s - loss: 4.4271 - acc: 0.1220 - val_loss: 4.2143 - val_acc: 0.1432\n",
      "Epoch 3/30\n",
      " - 130s - loss: 4.3832 - acc: 0.1224 - val_loss: 4.1858 - val_acc: 0.1432\n",
      "Epoch 4/30\n",
      " - 130s - loss: 4.3478 - acc: 0.1217 - val_loss: 4.1469 - val_acc: 0.1432\n",
      "Epoch 5/30\n",
      " - 130s - loss: 4.3116 - acc: 0.1201 - val_loss: 4.1302 - val_acc: 0.1432\n",
      "Epoch 6/30\n",
      " - 130s - loss: 4.2848 - acc: 0.1223 - val_loss: 4.1247 - val_acc: 0.1432\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 59\n",
      "Train on 22514 samples, validate on 5559 samples\n",
      "Epoch 1/30\n",
      " - 169s - loss: 6.3590 - acc: 0.1329 - val_loss: 4.4284 - val_acc: 0.1049\n",
      "Epoch 2/30\n",
      " - 143s - loss: 4.3505 - acc: 0.1339 - val_loss: 4.3560 - val_acc: 0.1049\n",
      "Epoch 3/30\n",
      " - 143s - loss: 4.3026 - acc: 0.1349 - val_loss: 4.3400 - val_acc: 0.1049\n",
      "Epoch 4/30\n",
      " - 143s - loss: 4.2621 - acc: 0.1348 - val_loss: 4.3029 - val_acc: 0.1049\n",
      "Epoch 5/30\n",
      " - 143s - loss: 4.2276 - acc: 0.1347 - val_loss: 4.2639 - val_acc: 0.1049\n",
      "Epoch 6/30\n",
      " - 143s - loss: 4.2009 - acc: 0.1335 - val_loss: 4.2331 - val_acc: 0.1049\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 74\n",
      "Train on 26558 samples, validate on 1515 samples\n",
      "Epoch 1/30\n",
      " - 190s - loss: 6.0931 - acc: 0.1246 - val_loss: 4.2139 - val_acc: 0.1406\n",
      "Epoch 2/30\n",
      " - 161s - loss: 4.3551 - acc: 0.1275 - val_loss: 4.1689 - val_acc: 0.1406\n",
      "Epoch 3/30\n",
      " - 161s - loss: 4.3055 - acc: 0.1274 - val_loss: 4.1054 - val_acc: 0.1406\n",
      "Epoch 4/30\n",
      " - 164s - loss: 4.2618 - acc: 0.1270 - val_loss: 4.0791 - val_acc: 0.1406\n",
      "Epoch 5/30\n",
      " - 161s - loss: 4.2257 - acc: 0.1270 - val_loss: 4.0663 - val_acc: 0.1406\n",
      "Epoch 6/30\n",
      " - 161s - loss: 4.1964 - acc: 0.1259 - val_loss: 4.0355 - val_acc: 0.1406\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 95\n",
      "Train on 26795 samples, validate on 1278 samples\n",
      "Epoch 1/30\n",
      " - 192s - loss: 6.0315 - acc: 0.1283 - val_loss: 4.9199 - val_acc: 0.0806\n",
      "Epoch 2/30\n",
      " - 163s - loss: 4.3167 - acc: 0.1297 - val_loss: 4.9119 - val_acc: 0.0806\n",
      "Epoch 3/30\n",
      " - 163s - loss: 4.2605 - acc: 0.1290 - val_loss: 4.8446 - val_acc: 0.0806\n",
      "Epoch 4/30\n",
      " - 163s - loss: 4.2187 - acc: 0.1298 - val_loss: 4.8480 - val_acc: 0.0806\n",
      "Epoch 5/30\n",
      " - 163s - loss: 4.1806 - acc: 0.1313 - val_loss: 4.8001 - val_acc: 0.0806\n",
      "Epoch 6/30\n",
      " - 163s - loss: 4.1512 - acc: 0.1300 - val_loss: 4.8197 - val_acc: 0.0806\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Checking regstrength 0.1\n",
      "\n",
      "Validating on opus 127\n",
      "Train on 25863 samples, validate on 2210 samples\n",
      "Epoch 1/30\n",
      " - 188s - loss: 7.9556 - acc: 0.1272 - val_loss: 4.7388 - val_acc: 0.1253\n",
      "Epoch 2/30\n",
      " - 158s - loss: 4.4910 - acc: 0.1280 - val_loss: 4.6321 - val_acc: 0.1253\n",
      "Epoch 3/30\n",
      " - 158s - loss: 4.3950 - acc: 0.1272 - val_loss: 4.5334 - val_acc: 0.1253\n",
      "Epoch 4/30\n",
      " - 158s - loss: 4.3173 - acc: 0.1293 - val_loss: 4.4879 - val_acc: 0.1253\n",
      "Epoch 5/30\n",
      " - 158s - loss: 4.2584 - acc: 0.1283 - val_loss: 4.4346 - val_acc: 0.1253\n",
      "Epoch 6/30\n",
      " - 158s - loss: 4.2077 - acc: 0.1283 - val_loss: 4.3718 - val_acc: 0.1253\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 130\n",
      "Train on 25609 samples, validate on 2464 samples\n",
      "Epoch 1/30\n",
      " - 188s - loss: 7.9425 - acc: 0.1245 - val_loss: 4.3183 - val_acc: 0.1530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      " - 158s - loss: 4.5305 - acc: 0.1258 - val_loss: 4.2249 - val_acc: 0.1530\n",
      "Epoch 3/30\n",
      " - 158s - loss: 4.4346 - acc: 0.1266 - val_loss: 4.1492 - val_acc: 0.0954\n",
      "Epoch 4/30\n",
      " - 158s - loss: 4.3584 - acc: 0.1253 - val_loss: 4.1046 - val_acc: 0.1530\n",
      "Epoch 5/30\n",
      " - 158s - loss: 4.2985 - acc: 0.1265 - val_loss: 4.0362 - val_acc: 0.1530\n",
      "Epoch 6/30\n",
      " - 158s - loss: 4.2470 - acc: 0.1252 - val_loss: 3.9938 - val_acc: 0.1530\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 131\n",
      "Train on 25519 samples, validate on 2554 samples\n",
      "Epoch 1/30\n",
      " - 190s - loss: 7.9604 - acc: 0.1267 - val_loss: 4.4819 - val_acc: 0.1316\n",
      "Epoch 2/30\n",
      " - 158s - loss: 4.5101 - acc: 0.1268 - val_loss: 4.3822 - val_acc: 0.1316\n",
      "Epoch 3/30\n",
      " - 158s - loss: 4.4154 - acc: 0.1274 - val_loss: 4.3322 - val_acc: 0.1316\n",
      "Epoch 4/30\n",
      " - 158s - loss: 4.3367 - acc: 0.1276 - val_loss: 4.2714 - val_acc: 0.1316\n",
      "Epoch 5/30\n",
      " - 158s - loss: 4.2748 - acc: 0.1268 - val_loss: 4.2357 - val_acc: 0.1316\n",
      "Epoch 6/30\n",
      " - 158s - loss: 4.2243 - acc: 0.1278 - val_loss: 4.1996 - val_acc: 0.1316\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 132\n",
      "Train on 25649 samples, validate on 2424 samples\n",
      "Epoch 1/30\n",
      " - 191s - loss: 7.9228 - acc: 0.1263 - val_loss: 4.9734 - val_acc: 0.0569\n",
      "Epoch 2/30\n",
      " - 159s - loss: 4.4599 - acc: 0.1291 - val_loss: 4.8621 - val_acc: 0.1139\n",
      "Epoch 3/30\n",
      " - 159s - loss: 4.3599 - acc: 0.1282 - val_loss: 4.7757 - val_acc: 0.1139\n",
      "Epoch 4/30\n",
      " - 158s - loss: 4.2821 - acc: 0.1289 - val_loss: 4.7533 - val_acc: 0.1139\n",
      "Epoch 5/30\n",
      " - 158s - loss: 4.2164 - acc: 0.1287 - val_loss: 4.7037 - val_acc: 0.1139\n",
      "Epoch 6/30\n",
      " - 159s - loss: 4.1675 - acc: 0.1282 - val_loss: 4.6673 - val_acc: 0.1139\n",
      "Epoch 7/30\n",
      " - 159s - loss: 4.1263 - acc: 0.1288 - val_loss: 4.6518 - val_acc: 0.1139\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "Validating on opus 135\n",
      "Train on 26570 samples, validate on 1503 samples\n",
      "Epoch 1/30\n",
      " - 196s - loss: 7.8170 - acc: 0.1245 - val_loss: 4.6596 - val_acc: 0.1564\n",
      "Epoch 2/30\n",
      " - 163s - loss: 4.4932 - acc: 0.1266 - val_loss: 4.5745 - val_acc: 0.1564\n",
      "Epoch 3/30\n",
      " - 163s - loss: 4.3938 - acc: 0.1262 - val_loss: 4.5307 - val_acc: 0.1564\n",
      "Epoch 4/30\n",
      " - 163s - loss: 4.3133 - acc: 0.1259 - val_loss: 4.4650 - val_acc: 0.1564\n",
      "Epoch 5/30\n",
      " - 163s - loss: 4.2523 - acc: 0.1262 - val_loss: 4.4131 - val_acc: 0.1564\n",
      "Epoch 6/30\n",
      " - 163s - loss: 4.2014 - acc: 0.1266 - val_loss: 4.3744 - val_acc: 0.1564\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 18\n",
      "Train on 19584 samples, validate on 8489 samples\n",
      "Epoch 1/30\n",
      " - 166s - loss: 9.0513 - acc: 0.1191 - val_loss: 4.4588 - val_acc: 0.1432\n",
      "Epoch 2/30\n",
      " - 132s - loss: 4.6023 - acc: 0.1221 - val_loss: 4.3659 - val_acc: 0.1432\n",
      "Epoch 3/30\n",
      " - 132s - loss: 4.5205 - acc: 0.1216 - val_loss: 4.3095 - val_acc: 0.1432\n",
      "Epoch 4/30\n",
      " - 132s - loss: 4.4511 - acc: 0.1220 - val_loss: 4.2558 - val_acc: 0.1432\n",
      "Epoch 5/30\n",
      " - 132s - loss: 4.3933 - acc: 0.1232 - val_loss: 4.2052 - val_acc: 0.1432\n",
      "Epoch 6/30\n",
      " - 132s - loss: 4.3436 - acc: 0.1229 - val_loss: 4.1662 - val_acc: 0.1432\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 59\n",
      "Train on 22514 samples, validate on 5559 samples\n",
      "Epoch 1/30\n",
      " - 179s - loss: 8.3515 - acc: 0.1331 - val_loss: 4.6188 - val_acc: 0.1049\n",
      "Epoch 2/30\n",
      " - 144s - loss: 4.5169 - acc: 0.1352 - val_loss: 4.5021 - val_acc: 0.1049\n",
      "Epoch 3/30\n",
      " - 144s - loss: 4.4278 - acc: 0.1334 - val_loss: 4.4457 - val_acc: 0.1049\n",
      "Epoch 4/30\n",
      " - 144s - loss: 4.3535 - acc: 0.1352 - val_loss: 4.3980 - val_acc: 0.1049\n",
      "Epoch 5/30\n",
      " - 144s - loss: 4.2920 - acc: 0.1352 - val_loss: 4.3271 - val_acc: 0.1049\n",
      "Epoch 6/30\n",
      " - 144s - loss: 4.2449 - acc: 0.1347 - val_loss: 4.2861 - val_acc: 0.1049\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 74\n",
      "Train on 26558 samples, validate on 1515 samples\n",
      "Epoch 1/30\n",
      " - 199s - loss: 7.8670 - acc: 0.1247 - val_loss: 4.4152 - val_acc: 0.1406\n",
      "Epoch 2/30\n",
      " - 163s - loss: 4.5087 - acc: 0.1273 - val_loss: 4.3025 - val_acc: 0.1406\n",
      "Epoch 3/30\n",
      " - 163s - loss: 4.4142 - acc: 0.1271 - val_loss: 4.2242 - val_acc: 0.1406\n",
      "Epoch 4/30\n",
      " - 163s - loss: 4.3361 - acc: 0.1273 - val_loss: 4.1563 - val_acc: 0.1406\n",
      "Epoch 5/30\n",
      " - 163s - loss: 4.2753 - acc: 0.1275 - val_loss: 4.1049 - val_acc: 0.1406\n",
      "Epoch 6/30\n",
      " - 163s - loss: 4.2220 - acc: 0.1277 - val_loss: 4.0611 - val_acc: 0.1406\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 95\n",
      "Train on 26795 samples, validate on 1278 samples\n",
      "Epoch 1/30\n",
      " - 205s - loss: 7.7282 - acc: 0.1294 - val_loss: 5.0497 - val_acc: 0.0806\n",
      "Epoch 2/30\n",
      " - 165s - loss: 4.4712 - acc: 0.1302 - val_loss: 4.9717 - val_acc: 0.0806\n",
      "Epoch 3/30\n",
      " - 200s - loss: 4.3698 - acc: 0.1303 - val_loss: 4.9118 - val_acc: 0.0806\n",
      "Epoch 4/30\n",
      " - 182s - loss: 4.2921 - acc: 0.1308 - val_loss: 4.8589 - val_acc: 0.0806\n",
      "Epoch 5/30\n",
      " - 165s - loss: 4.2289 - acc: 0.1317 - val_loss: 4.8429 - val_acc: 0.0806\n",
      "Epoch 6/30\n",
      " - 165s - loss: 4.1776 - acc: 0.1311 - val_loss: 4.8206 - val_acc: 0.0806\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Checking regstrength 0.5\n",
      "\n",
      "Validating on opus 127\n",
      "Train on 25863 samples, validate on 2210 samples\n",
      "Epoch 1/30\n",
      " - 199s - loss: 21.4679 - acc: 0.1280 - val_loss: 5.2686 - val_acc: 0.1253\n",
      "Epoch 2/30\n",
      " - 160s - loss: 4.9162 - acc: 0.1282 - val_loss: 4.9329 - val_acc: 0.1253\n",
      "Epoch 3/30\n",
      " - 160s - loss: 4.6199 - acc: 0.1282 - val_loss: 4.6761 - val_acc: 0.1253\n",
      "Epoch 4/30\n",
      " - 160s - loss: 4.4154 - acc: 0.1272 - val_loss: 4.5099 - val_acc: 0.1253\n",
      "Epoch 5/30\n",
      " - 160s - loss: 4.2736 - acc: 0.1287 - val_loss: 4.4131 - val_acc: 0.1253\n",
      "Epoch 6/30\n",
      " - 160s - loss: 4.1747 - acc: 0.1271 - val_loss: 4.3380 - val_acc: 0.1253\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 130\n",
      "Train on 25609 samples, validate on 2464 samples\n",
      "Epoch 1/30\n",
      " - 198s - loss: 21.5198 - acc: 0.1247 - val_loss: 4.9524 - val_acc: 0.1530\n",
      "Epoch 2/30\n",
      " - 157s - loss: 4.9538 - acc: 0.1260 - val_loss: 4.5931 - val_acc: 0.1530\n",
      "Epoch 3/30\n",
      " - 157s - loss: 4.6620 - acc: 0.1259 - val_loss: 4.3306 - val_acc: 0.1530\n",
      "Epoch 4/30\n",
      " - 157s - loss: 4.4561 - acc: 0.1260 - val_loss: 4.1800 - val_acc: 0.1530\n",
      "Epoch 5/30\n",
      " - 157s - loss: 4.3151 - acc: 0.1254 - val_loss: 4.0510 - val_acc: 0.1530\n",
      "Epoch 6/30\n",
      " - 157s - loss: 4.2157 - acc: 0.1253 - val_loss: 3.9624 - val_acc: 0.1530\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 131\n",
      "Train on 25519 samples, validate on 2554 samples\n",
      "Epoch 1/30\n",
      " - 198s - loss: 21.4842 - acc: 0.1263 - val_loss: 5.0821 - val_acc: 0.1316\n",
      "Epoch 2/30\n",
      " - 157s - loss: 4.9412 - acc: 0.1286 - val_loss: 4.7140 - val_acc: 0.1316\n",
      "Epoch 3/30\n",
      " - 157s - loss: 4.6427 - acc: 0.1284 - val_loss: 4.4892 - val_acc: 0.1316\n",
      "Epoch 4/30\n",
      " - 157s - loss: 4.4365 - acc: 0.1279 - val_loss: 4.3437 - val_acc: 0.1316\n",
      "Epoch 5/30\n",
      " - 157s - loss: 4.2936 - acc: 0.1265 - val_loss: 4.2209 - val_acc: 0.1316\n",
      "Epoch 6/30\n",
      " - 157s - loss: 4.1951 - acc: 0.1287 - val_loss: 4.1401 - val_acc: 0.1316\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 132\n",
      "Train on 25649 samples, validate on 2424 samples\n",
      "Epoch 1/30\n",
      " - 199s - loss: 21.5039 - acc: 0.1292 - val_loss: 5.4344 - val_acc: 0.1139\n",
      "Epoch 2/30\n",
      " - 158s - loss: 4.8883 - acc: 0.1296 - val_loss: 5.1034 - val_acc: 0.1139\n",
      "Epoch 3/30\n",
      " - 158s - loss: 4.5874 - acc: 0.1300 - val_loss: 4.8841 - val_acc: 0.1139\n",
      "Epoch 4/30\n",
      " - 158s - loss: 4.3798 - acc: 0.1300 - val_loss: 4.7376 - val_acc: 0.1139\n",
      "Epoch 5/30\n",
      " - 158s - loss: 4.2362 - acc: 0.1293 - val_loss: 4.6570 - val_acc: 0.1139\n",
      "Epoch 6/30\n",
      " - 158s - loss: 4.1373 - acc: 0.1297 - val_loss: 4.5826 - val_acc: 0.1139\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 135\n",
      "Train on 26570 samples, validate on 1503 samples\n",
      "Epoch 1/30\n",
      " - 205s - loss: 21.0200 - acc: 0.1249 - val_loss: 5.1919 - val_acc: 0.1564\n",
      "Epoch 2/30\n",
      " - 162s - loss: 4.9031 - acc: 0.1274 - val_loss: 4.8742 - val_acc: 0.1564\n",
      "Epoch 3/30\n",
      " - 163s - loss: 4.6023 - acc: 0.1273 - val_loss: 4.6295 - val_acc: 0.0765\n",
      "Epoch 4/30\n",
      " - 162s - loss: 4.3984 - acc: 0.1265 - val_loss: 4.4787 - val_acc: 0.1564\n",
      "Epoch 5/30\n",
      " - 162s - loss: 4.2588 - acc: 0.1268 - val_loss: 4.3986 - val_acc: 0.0765\n",
      "Epoch 6/30\n",
      " - 162s - loss: 4.1641 - acc: 0.1258 - val_loss: 4.3178 - val_acc: 0.1564\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 18\n",
      "Train on 19584 samples, validate on 8489 samples\n",
      "Epoch 1/30\n",
      " - 177s - loss: 26.5913 - acc: 0.1214 - val_loss: 5.1299 - val_acc: 0.1432\n",
      "Epoch 2/30\n",
      " - 165s - loss: 5.1191 - acc: 0.1226 - val_loss: 4.8265 - val_acc: 0.1432\n",
      "Epoch 3/30\n",
      " - 144s - loss: 4.8519 - acc: 0.1226 - val_loss: 4.5899 - val_acc: 0.1432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      " - 137s - loss: 4.6497 - acc: 0.1228 - val_loss: 4.4328 - val_acc: 0.1432\n",
      "Epoch 5/30\n",
      " - 131s - loss: 4.4964 - acc: 0.1228 - val_loss: 4.3113 - val_acc: 0.1051\n",
      "Epoch 6/30\n",
      " - 132s - loss: 4.3798 - acc: 0.1229 - val_loss: 4.2002 - val_acc: 0.1432\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 59\n",
      "Train on 22514 samples, validate on 5559 samples\n",
      "Epoch 1/30\n",
      " - 189s - loss: 23.8109 - acc: 0.1342 - val_loss: 5.2206 - val_acc: 0.1049\n",
      "Epoch 2/30\n",
      " - 144s - loss: 4.9877 - acc: 0.1352 - val_loss: 4.8969 - val_acc: 0.1049\n",
      "Epoch 3/30\n",
      " - 144s - loss: 4.7059 - acc: 0.1349 - val_loss: 4.6324 - val_acc: 0.1049\n",
      "Epoch 4/30\n",
      " - 144s - loss: 4.5010 - acc: 0.1344 - val_loss: 4.4866 - val_acc: 0.1049\n",
      "Epoch 5/30\n",
      " - 144s - loss: 4.3532 - acc: 0.1352 - val_loss: 4.3577 - val_acc: 0.1049\n",
      "Epoch 6/30\n",
      " - 144s - loss: 4.2450 - acc: 0.1351 - val_loss: 4.2386 - val_acc: 0.1049\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 74\n",
      "Train on 26558 samples, validate on 1515 samples\n",
      "Epoch 1/30\n",
      " - 207s - loss: 20.9321 - acc: 0.1267 - val_loss: 4.9839 - val_acc: 0.1406\n",
      "Epoch 2/30\n",
      " - 173s - loss: 4.9225 - acc: 0.1278 - val_loss: 4.6182 - val_acc: 0.1406\n",
      "Epoch 3/30\n",
      " - 177s - loss: 4.6274 - acc: 0.1281 - val_loss: 4.3976 - val_acc: 0.1406\n",
      "Epoch 4/30\n",
      " - 172s - loss: 4.4224 - acc: 0.1281 - val_loss: 4.2094 - val_acc: 0.1406\n",
      "Epoch 5/30\n",
      " - 161s - loss: 4.2828 - acc: 0.1271 - val_loss: 4.0911 - val_acc: 0.1406\n",
      "Epoch 6/30\n",
      " - 161s - loss: 4.1870 - acc: 0.1275 - val_loss: 4.0483 - val_acc: 0.0950\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 95\n",
      "Train on 26795 samples, validate on 1278 samples\n",
      "Epoch 1/30\n",
      " - 210s - loss: 20.7011 - acc: 0.1303 - val_loss: 5.4883 - val_acc: 0.0806\n",
      "Epoch 2/30\n",
      " - 162s - loss: 4.8800 - acc: 0.1313 - val_loss: 5.1785 - val_acc: 0.0806\n",
      "Epoch 3/30\n",
      " - 162s - loss: 4.5778 - acc: 0.1300 - val_loss: 4.9945 - val_acc: 0.0806\n",
      "Epoch 4/30\n",
      " - 162s - loss: 4.3711 - acc: 0.1314 - val_loss: 4.8663 - val_acc: 0.0806\n",
      "Epoch 5/30\n",
      " - 162s - loss: 4.2328 - acc: 0.1313 - val_loss: 4.7760 - val_acc: 0.0806\n",
      "Epoch 6/30\n",
      " - 162s - loss: 4.1372 - acc: 0.1316 - val_loss: 4.7212 - val_acc: 0.0806\n",
      "Epoch 00006: early stopping\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#define the range of regularization strengths to check\n",
    "regstrength = [0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "print(\"Start!\")\n",
    "\n",
    "#Create container for results\n",
    "RESULTS = pd.DataFrame()\n",
    "\n",
    "for strength in regstrength:\n",
    "    print(\"\\nChecking regstrength {}\".format(strength))\n",
    "    cv_results = pd.DataFrame()\n",
    "    \n",
    "    #Cross validate on each opus\n",
    "    for opus in data['op'].unique():\n",
    "        print(\"\\nValidating on opus {}\".format(opus))\n",
    "\n",
    "        #Split into training and validation\n",
    "        valid = data[data['op'] == opus]\n",
    "        train = data[data['op'] != opus]\n",
    "\n",
    "        #Drop the opus attribute since it's no longer needed\n",
    "        valid = valid.drop(columns='op')\n",
    "        train = train.drop(columns='op')\n",
    "\n",
    "        #Generate sequences from the data\n",
    "        valid_in, valid_out = generate_sequences(valid, valid, seq_length)\n",
    "        train_in, train_out = generate_sequences(train, train, seq_length)\n",
    "\n",
    "        #Create model\n",
    "        model = lstm(train_in, train_out, optimizer, loss, metrics, strength)\n",
    "\n",
    "        #Train on the folds\n",
    "        model.fit(train_in,\n",
    "                  train_out,\n",
    "                  epochs = epochs,\n",
    "                  verbose = verbose,\n",
    "                  validation_data = (valid_in, valid_out),\n",
    "                  callbacks = callbacks_list)\n",
    "\n",
    "        #Save the history object for the model, appending test opus and regstrength\n",
    "        history = pd.DataFrame(model.history.history)\n",
    "        history.index.name = 'epoch'\n",
    "        history['opus'] = opus\n",
    "        history['reg'] = strength\n",
    "        cv_results = cv_results.append(history)\n",
    "    \n",
    "    RESULTS = RESULTS.append(cv_results)\n",
    "\n",
    "print(\"Done!\")\n",
    "pd.DataFrame.to_csv(RESULTS, './results/BACKUP.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weigh results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Buffer has wrong number of dimensions (expected 1, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-ab1acbff37b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mRESULTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#Get the opus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mopus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRESULTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#Count the chords in it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2089\u001b[0m         \u001b[0;31m# a list of integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m         \u001b[0;31m# a single integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2068\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2070\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2071\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m             \u001b[0;31m# re-raise with different error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, is_copy)\u001b[0m\n\u001b[1;32m   2784\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   2785\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2786\u001b[0;31m                                    verify=True)\n\u001b[0m\u001b[1;32m   2787\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   4537\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4538\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 4539\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   4540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   4423\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   4424\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 4425\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   4426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4427\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4423\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   4424\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 4425\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   4426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4427\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[0;32m-> 1258\u001b[0;31m                                        allow_fill=True, fill_value=fill_value)\n\u001b[0m\u001b[1;32m   1259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1654\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n\u001b[1;32m   1655\u001b[0m                                  mask_info=mask_info)\n\u001b[0;32m-> 1656\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/algos_take_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.algos.take_2d_axis1_float64_float64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Buffer has wrong number of dimensions (expected 1, got 2)"
     ]
    }
   ],
   "source": [
    "RESULTS = pd.read_csv('results/BACKUP.csv')\n",
    "for index, row in RESULTS.iterrows():\n",
    "    #Get the opus\n",
    "    opus = RESULTS.iloc[[index]].opus.values[0]\n",
    "    \n",
    "    #Count the chords in it\n",
    "    weight = (data[data['op'] == opus]).shape[0]\n",
    "    \n",
    "    #Multiply the metrics by the weight\n",
    "    row = RESULTS.iloc[[index]]\n",
    "    row[['val_loss', 'val_acc', 'loss', 'acc']] *= weight\n",
    "    \n",
    "    #Overwrite the old data in the RESULTS\n",
    "    RESULTS.iloc[[index]] = row\n",
    "    if(index%20 == 0):\n",
    "        print(\"{0:.2f} percent done\".format(index/RESULTS.shape[0]))\n",
    "        \n",
    "print(\"Done!\")\n",
    "pd.DataFrame.to_csv(RESULTS, './results/WEIGHED_BACKUP.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select which results to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select to load the weighed or the unweighed results\n",
    "RESULTS = pd.read_csv('results/WEIGHED_BACKUP.csv')\n",
    "RESULTS = pd.read_csv('results/BACKUP.csv')\n",
    "    \n",
    "#Reindex\n",
    "RESULTS = RESULTS.set_index(['reg','opus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each regularization value, calculate the average cross-validated score and output it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full table of cross validated scores for each regularization value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000</th>\n",
       "      <td>3.641026</td>\n",
       "      <td>4.167775</td>\n",
       "      <td>0.131346</td>\n",
       "      <td>3.936454</td>\n",
       "      <td>0.133513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>2.528302</td>\n",
       "      <td>4.103910</td>\n",
       "      <td>0.127975</td>\n",
       "      <td>4.055110</td>\n",
       "      <td>0.124874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005</th>\n",
       "      <td>2.404255</td>\n",
       "      <td>4.172407</td>\n",
       "      <td>0.129148</td>\n",
       "      <td>4.106369</td>\n",
       "      <td>0.124472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>2.490196</td>\n",
       "      <td>4.194825</td>\n",
       "      <td>0.127646</td>\n",
       "      <td>4.183819</td>\n",
       "      <td>0.126107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.050</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.366877</td>\n",
       "      <td>0.127714</td>\n",
       "      <td>4.586606</td>\n",
       "      <td>0.127213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>2.622642</td>\n",
       "      <td>4.457916</td>\n",
       "      <td>0.127237</td>\n",
       "      <td>4.910315</td>\n",
       "      <td>0.127721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>2.400000</td>\n",
       "      <td>4.655938</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>7.689694</td>\n",
       "      <td>0.128297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          epoch  val_loss   val_acc      loss       acc\n",
       "0.000  3.641026  4.167775  0.131346  3.936454  0.133513\n",
       "0.001  2.528302  4.103910  0.127975  4.055110  0.124874\n",
       "0.005  2.404255  4.172407  0.129148  4.106369  0.124472\n",
       "0.010  2.490196  4.194825  0.127646  4.183819  0.126107\n",
       "0.050  2.500000  4.366877  0.127714  4.586606  0.127213\n",
       "0.100  2.622642  4.457916  0.127237  4.910315  0.127721\n",
       "0.500  2.400000  4.655938  0.126000  7.689694  0.128297"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>3.641026</td>\n",
       "      <td>4.167775</td>\n",
       "      <td>0.131346</td>\n",
       "      <td>3.936454</td>\n",
       "      <td>0.133513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        epoch  val_loss   val_acc      loss       acc\n",
       "0.0  3.641026  4.167775  0.131346  3.936454  0.133513"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AVERAGES = pd.DataFrame()\n",
    "\n",
    "#For each level of regularization\n",
    "for regularization, cvscores in RESULTS.groupby(level=0):\n",
    "    average = pd.DataFrame()\n",
    "    \n",
    "    #Iterate through all folds and extract the highest validation scores\n",
    "    for opus, fold in cvscores.groupby(level=1):\n",
    "\n",
    "        #Retrieve the best score\n",
    "        best = fold[fold['val_acc'] == fold['val_acc'].max()]\n",
    "        average = average.append(best)\n",
    "    \n",
    "    #Make a pretty dataframe of the mean\n",
    "    average = average.describe().loc[['mean']]\n",
    "    average = average.rename(index={'mean': regularization})\n",
    "    \n",
    "    #Take the mean scores for this regularization value and store them in AVERAGE for comparisons\n",
    "    AVERAGES = AVERAGES.append(average)\n",
    "\n",
    "BEST = AVERAGES[AVERAGES['val_acc'] == AVERAGES['val_acc'].max()]\n",
    "\n",
    "print(\"Full table of cross validated scores for each regularization value\")\n",
    "display(AVERAGES)\n",
    "\n",
    "print(\"Best score\")\n",
    "display(BEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chords in each opus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sizes = data.groupby('op')[['chord_#I']].count()\n",
    "sizes = sizes.rename(columns={'chord_#I': 'count'})\n",
    "#sizes = sizes.sort_values(by = 'count', ascending=False)\n",
    "sizes = sizes.append(sizes.describe().loc[['mean']])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.barplot(data=sizes.T)\n",
    "ax.set_title(\"Amount of chords in each opus\")\n",
    "ax.set_ylabel(\"Chords\")\n",
    "ax.set_xlabel(\"Opus\")\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"./figs/chords_per_opus.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation accuracy for each opus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Use the data from the reg_value that produced the best results\n",
    "best_reg = BEST.index.values[0]\n",
    "df = RESULTS.loc[best_reg]\n",
    "\n",
    "#For each of the nine folds/opuses...\n",
    "scores = pd.DataFrame()\n",
    "for opus, fold in df.groupby(level=0):\n",
    "        \n",
    "        #Drop potential duplicate values\n",
    "        fold = fold.drop_duplicates(subset='val_acc')\n",
    "        \n",
    "        #Retrieve the scores when the val_acc was highest\n",
    "        score = fold[fold['val_acc'] == fold['val_acc'].max()]\n",
    "        \n",
    "        #Store\n",
    "        scores = scores.append(score)\n",
    "\n",
    "#Sort scores by valacc\n",
    "#scores = scores.sort_values(by='val_acc', ascending=False)\n",
    "\n",
    "#Append the average score to the individual scores\n",
    "avg = BEST.rename(index={best_reg: 'mean'})\n",
    "    \n",
    "scores = scores.append(avg)\n",
    "\n",
    "#Plot them\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.barplot(data=scores[['val_acc']].T)\n",
    "#ax.set_title(\"Weighed accuracy on each opus\")\n",
    "ax.set_title(\"Accuracy on each opus\")\n",
    "ax.set_ylabel(\"Accuracy (%)\")\n",
    "ax.set_xlabel(\"Opus\")\n",
    "ax.set_yticklabels(np.around(ax.get_yticks()* 100,2))\n",
    "#fig.savefig(\"./figs/Weighed_NNacc_V.png\")\n",
    "fig.savefig(\"./figs/NNacc_V.png\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,15))\n",
    "sns.barplot(data=scores[['val_acc']].T, orient='horizontal')\n",
    "#ax.set_title(\"Weighed accuracy on each opus\")\n",
    "ax.set_title(\"Accuracy on each opus\")\n",
    "ax.set_xlabel(\"Accuracy (%)\")\n",
    "ax.set_ylabel(\"Opus\")\n",
    "ax.set_xticklabels(np.around(ax.get_xticks()* 100,2))\n",
    "#fig.savefig(\"./figs/Weighed_NNacc_H.png\")\n",
    "fig.savefig(\"./figs/NNacc_H.png\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
