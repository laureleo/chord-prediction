{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes from run-1\n",
    "\n",
    "#### Test data\n",
    "* Previously we used cross-validation to select the best model, and tested that model on data (opus 131) that we had kept apart from the beginning.\n",
    "* The scores achieved when predicting on opus 131 were our final results.\n",
    "* This time we train/validate on all data and take the final cross-validation scores as our results.\n",
    "\n",
    "#### Crossvalidation\n",
    "* Previously we simply took all sequences in the train/validate set, shuffled them and trained/validated with a 80/20 split.\n",
    "* This time we instead shuffle the opuses (opi?) before generating the sequences, with the idea that this will be a more correct estimate of how patterns generalize across opuses with leave one (opus) out cross validation.\n",
    "\n",
    "#### Input\n",
    "* Previously we grouped similar chords together and grouped chords that appeared rarely (less than 10 times) under a single label.\n",
    "* The idea was to remove outliers, reduce the output space and improve generalization\n",
    "* As it was indicated that having the amount of output classes be dependent on the input was a bad idea we now use rules independent of the data for grouping (?)\n",
    "\n",
    "#### Model\n",
    "* Previously we had a bi-directional LSTM layer in the model architecture as it increased performance. For the sake of being able to compare the results to a simple N-gram model we decided to remove that layer in this iteration.\n",
    "\n",
    "#### Hyperparameters\n",
    "* Given the increased amount of outliers and the removal of the bidirectional layer we expect generalization accuracy to decrease.\n",
    "* To remedy that we used the current model and iterated through different values for a regularization parameter, which we didn't explore previously.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sigis/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "from chord_functions import *\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "\n",
    "#Load all data\n",
    "data = pd.read_csv('data/820chords.csv')\n",
    "\n",
    "#Remove redundant attributes. Keep op to split into opuses\n",
    "data = data[['chord', 'op']]\n",
    "\n",
    "#Use dummy variable representation for the chords\n",
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(lstm_x, lstm_y, optimizer, loss, metrics, regstrength):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences=True, input_shape=(lstm_x.shape[1], lstm_x.shape[2]),\\\n",
    "                   kernel_regularizer=regularizers.l2(regstrength)))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(LSTM(64, return_sequences=False,\\\n",
    "              kernel_regularizer=regularizers.l2(regstrength)))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(lstm_y.shape[1], activation='softmax', \\\n",
    "             kernel_regularizer=regularizers.l2(regstrength)))\n",
    "\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select parameters for the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = 'Adam'\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "epochs = 10\n",
    "verbose = 2\n",
    "seq_length = 10\n",
    "\n",
    "#Save the weights whenever validation accuracy is increased\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'weights.{epoch:02d}-{val_acc:.4f}.hdf5',\n",
    "    monitor='val_acc', \n",
    "    verbose=0,        \n",
    "    save_best_only=False\n",
    ")\n",
    "# Stop the learning process if we havent improved validation accuracy for 10 epochs\n",
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1)\n",
    "\n",
    "#callbacks_list = [checkpoint, earlystop]   \n",
    "callbacks_list = [earlystop]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start!\n",
      "\n",
      "Checking regstrength 0\n",
      "\n",
      "Validating on opus 74\n",
      "Train on 26558 samples, validate on 1515 samples\n",
      "Epoch 1/10\n",
      " - 170s - loss: 4.1009 - acc: 0.1174 - val_loss: 3.8080 - val_acc: 0.1406\n",
      "Epoch 2/10\n",
      " - 170s - loss: 3.9862 - acc: 0.1252 - val_loss: 3.7991 - val_acc: 0.1406\n",
      "Epoch 3/10\n",
      " - 170s - loss: 3.9790 - acc: 0.1249 - val_loss: 3.8172 - val_acc: 0.1406\n",
      "Epoch 4/10\n",
      " - 172s - loss: 3.9798 - acc: 0.1272 - val_loss: 3.8267 - val_acc: 0.1406\n",
      "Epoch 5/10\n",
      " - 167s - loss: 3.9767 - acc: 0.1260 - val_loss: 3.8090 - val_acc: 0.1406\n",
      "Epoch 6/10\n",
      " - 168s - loss: 4.0793 - acc: 0.1307 - val_loss: 3.7756 - val_acc: 0.1406\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 59\n",
      "Train on 22514 samples, validate on 5559 samples\n",
      "Epoch 1/10\n",
      " - 149s - loss: 4.1048 - acc: 0.1257 - val_loss: 3.9729 - val_acc: 0.1049\n",
      "Epoch 2/10\n",
      " - 147s - loss: 3.9795 - acc: 0.1307 - val_loss: 4.0072 - val_acc: 0.1049\n",
      "Epoch 3/10\n",
      " - 148s - loss: 3.9699 - acc: 0.1328 - val_loss: 4.0204 - val_acc: 0.1049\n",
      "Epoch 4/10\n",
      " - 147s - loss: 3.9676 - acc: 0.1339 - val_loss: 4.0413 - val_acc: 0.1049\n",
      "Epoch 5/10\n",
      " - 159s - loss: 3.9668 - acc: 0.1325 - val_loss: 4.0304 - val_acc: 0.1049\n",
      "Epoch 6/10\n",
      " - 156s - loss: 3.9659 - acc: 0.1340 - val_loss: 4.0430 - val_acc: 0.1049\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Validating on opus 95\n",
      "Train on 26795 samples, validate on 1278 samples\n",
      "Epoch 1/10\n",
      " - 177s - loss: 4.0568 - acc: 0.1244 - val_loss: 4.7889 - val_acc: 0.0806\n",
      "Epoch 2/10\n"
     ]
    }
   ],
   "source": [
    "#define the range of regularization strength to check\n",
    "regstrength = [0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "regstrength = [0, 0.1]\n",
    "print(\"Start!\")\n",
    "\n",
    "#Create container for results\n",
    "RESULTS = pd.DataFrame()\n",
    "\n",
    "for strength in regstrength:\n",
    "    print(\"\\nChecking regstrength {}\".format(strength))\n",
    "    cv_results = pd.DataFrame()\n",
    "    \n",
    "    #for opus in data['op'].unique():\n",
    "    for opus in [74, 59, 95, 18]:\n",
    "        print(\"\\nValidating on opus {}\".format(opus))\n",
    "\n",
    "        #Split into training and validation\n",
    "        valid = data[data['op'] == opus]\n",
    "        train = data[data['op'] != opus]\n",
    "\n",
    "        #Drop the opus attribute since it's no longer needed\n",
    "        valid = valid.drop(columns='op')\n",
    "        train = train.drop(columns='op')\n",
    "\n",
    "        #Generate sequences from the data\n",
    "        valid_in, valid_out = generate_sequences(valid, valid, seq_length)\n",
    "        train_in, train_out = generate_sequences(train, train, seq_length)\n",
    "\n",
    "        #Create model\n",
    "        model = lstm(train_in, train_out, optimizer, loss, metrics, strength)\n",
    "\n",
    "        #Train on the folds\n",
    "        model.fit(train_in,\n",
    "                  train_out,\n",
    "                  epochs = epochs,\n",
    "                  verbose = verbose,\n",
    "                  validation_data = (valid_in, valid_out),\n",
    "                  callbacks = callbacks_list)\n",
    "\n",
    "        #Save the history object for the model, appending test opus and regstrength\n",
    "        history = pd.DataFrame(model.history.history)\n",
    "        history.index.name = 'epoch'\n",
    "        history['opus'] = opus\n",
    "        history['reg'] = strength\n",
    "        cv_results = cv_results.append(history)\n",
    "    \n",
    "    RESULTS = RESULTS.append(cv_results)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKUP = RESULTS\n",
    "pd.DataFrame.to_csv(BACKUP, './results/BACKUP.csv')\n",
    "\n",
    "\n",
    "#OBS: Assumes that we are working with a multiindex\n",
    "\n",
    "AVERAGES = pd.DataFrame()\n",
    "\n",
    "#For each level of regularization\n",
    "for regularization, cvscores in RESULTS.groupby(level=0):\n",
    "    average = pd.DataFrame()\n",
    "    \n",
    "    #Iterate through all folds and extract the highest validation score for each fold\n",
    "    for opus, fold in cvscores.groupby(level=1):\n",
    "        best = fold[fold['val_acc'] == fold['val_acc'].max()]\n",
    "        average = average.append(best)\n",
    "    \n",
    "    #Make a pretty dataframe of the mean\n",
    "    average = average.describe().loc[['mean']]\n",
    "    average['reg'] = regularization\n",
    "    average = average.set_index(average['reg']).drop(columns='reg')\n",
    "    \n",
    "    #Take the mean scores for this regularization value and store them in AVERAGE for comparisons\n",
    "    AVERAGES = AVERAGES.append(average)\n",
    "\n",
    "BEST = AVERAGES[AVERAGES['val_acc'] == AVERAGES['val_acc'].max()]\n",
    "\n",
    "print(\"Full table of cross validated scores for each regularization value\")\n",
    "display(AVERAGES)\n",
    "\n",
    "print(\"Best score\")\n",
    "display(BEST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
