{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit tests\n",
    "Since the expressive power of Neural network should be at least comparable to our wonderful simple bi-gram model, we are suggested to run tests to see where the performance diverges\n",
    "\n",
    "Esentially:\n",
    "* Generate some test data that we can reason about what the accuracy SHOULD be\n",
    "* Test the bigram and the network\n",
    "* See if things are as expected \n",
    "* If no, find out why\n",
    "* If yes, try to come up with a new test\n",
    "* Since these are meant to be just quick checks, no need to cross validate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and functions/models to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sigis/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "from chord_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerator(test):\n",
    "    '''\n",
    "    Given sample of ngrams\n",
    "    Returns a marix where each entry is the number of times\n",
    "    given sequence is followed by given chord in training data\n",
    "    \n",
    "    '''\n",
    "    num_occ=np.zeros((test.shape[0],len(chords)))\n",
    "    for i in range(0,len(chords)):\n",
    "        chord=np.repeat(chords[i],(test.shape[0],))\n",
    "        chord=chord.reshape(test.shape[0],1)\n",
    "        temp=np.hstack([test, chord]) \n",
    "        num_occ[:,i]=denominator(ngram,temp)\n",
    "    return num_occ\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denominator(train,test):\n",
    "    '''\n",
    "    Given train and test samples of ngram sequences, \n",
    "    calculates the number of times each of the sequences in test occur in train.\n",
    "    Returns an array containing occurence number of each ngram sample in test\n",
    "    \n",
    "    '''\n",
    "    occ=np.zeros(test.shape[0])\n",
    "    for i in range(0,test.shape[0]):\n",
    "        bool_=(train==test[i])\n",
    "        occ[i]=np.sum(np.sum(bool_,axis=1)==test.shape[1])\n",
    "    return occ     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(lstm_x, lstm_y):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences=True, input_shape=(lstm_x.shape[1], lstm_x.shape[2])))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(lstm_y.shape[1], activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "\n",
    "#Load all data\n",
    "DF = pd.read_csv('data/820chords.csv')\n",
    "DF = DF[['chord']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: All  chord sequences are the same\n",
    "accuracy should be 100% for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate baseline input\n",
    "data = pd.DataFrame()\n",
    "for i in range(50):\n",
    "    data = data.append(DF.iloc[0])\n",
    "    data = data.append(DF.iloc[1])\n",
    "\n",
    "#Define split position\n",
    "split = round(len(data)*0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format data for LSTM\n",
    "n = 4\n",
    "dummies = pd.get_dummies(data)\n",
    "lstm_x, lstm_y = generate_sequences(dummies, dummies, n)\n",
    "\n",
    "lstm_x_train = lstm_x[:split]\n",
    "lstm_x_valid = lstm_x[split:]\n",
    "\n",
    "lstm_y_train = lstm_y[:split]\n",
    "lstm_y_valid = lstm_y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train NN\n",
    "model = lstm(lstm_x_train, lstm_y_train)\n",
    "model.fit(lstm_x_train,\n",
    "          lstm_y_train,\n",
    "          epochs = 10,\n",
    "          validation_data = (lstm_x_valid, lstm_y_valid),\n",
    "          verbose = 0)\n",
    "\n",
    "NN_result = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format data for ngram\n",
    "train = data[:split]\n",
    "valid = data[split:]\n",
    "\n",
    "n = 2\n",
    "chords=data.chord.unique()\n",
    "corpus=train.chord.values\n",
    "ngram= []\n",
    "\n",
    "#N gram generation: training\n",
    "for i in range(0,len(corpus) - (n +1)):\n",
    "    in_data = corpus[i:n + i]\n",
    "    ngram.append(in_data)\n",
    "    \n",
    "ngram=np.array(ngram)\n",
    "train_x=ngram[:,:n-1]\n",
    "train_y=ngram[:,-1]\n",
    "\n",
    "#N gram generation: validation\n",
    "corpus_val=valid.chord.values\n",
    "ngram_val=[]\n",
    "for i in range(0,len(corpus_val) - (n +1)):\n",
    "    in_data =corpus_val[i:n + i]\n",
    "    ngram_val.append(in_data)\n",
    "ngram_val=np.array(ngram_val)\n",
    "val_x=ngram_val[:,:n-1]\n",
    "val_y=ngram_val[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train NGRAM\n",
    "\n",
    "a=numerator(val_x)+1\n",
    "b=denominator(train_x,val_x)+len(chords)\n",
    "max_ind=np.zeros(val_x.shape[0])\n",
    "max_ind=np.argmax(a.T/b.T,axis=0)\n",
    "pred=np.empty((val_x.shape[0],1),dtype=\"<U10\")\n",
    "for i in range(0,len(pred)):\n",
    "    pred[i]=chords[max_ind[i]]\n",
    "result = np.sum(pred.flatten()==val_y)/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of validation accuracy\n",
      "Neural network: 1.0\n",
      "N-gram        : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparison of validation accuracy\")\n",
    "print(\"Neural network: {}\".format(NN_result.tail(1).val_acc.values[0]))\n",
    "print(\"N-gram        : {}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
