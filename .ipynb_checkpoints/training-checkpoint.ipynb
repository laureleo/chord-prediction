{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSPidSN8EUPA"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import itertools\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "xWhgtKrdGBTq",
    "outputId": "93dc8757-0fb4-4782-ec2d-606276aa382f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-377aa058-74c9-4bba-9d10-f14daea39ac9\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-377aa058-74c9-4bba-9d10-f14daea39ac9\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving updated_chords.csv to updated_chords (1).csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndVwSiRgEUPM"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"updated_chords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3MlXKvkhEUPV"
   },
   "outputs": [],
   "source": [
    "for i in range(0,df.shape[0]):\n",
    "    if ((df.chord==df.chord[i]).sum()<10):\n",
    "        df=df.replace(df.chord[i],'R')\n",
    "        df=df.replace(df.figbass[i],np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "BamRgVFGEUPd",
    "outputId": "0933864f-2ee5-4d3d-f356-33a7cc0967de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>chord</th>\n",
       "      <th>altchord</th>\n",
       "      <th>measure</th>\n",
       "      <th>beat</th>\n",
       "      <th>totbeat</th>\n",
       "      <th>timesig</th>\n",
       "      <th>op</th>\n",
       "      <th>no</th>\n",
       "      <th>mov</th>\n",
       "      <th>length</th>\n",
       "      <th>global_key</th>\n",
       "      <th>local_key</th>\n",
       "      <th>pedal</th>\n",
       "      <th>numeral</th>\n",
       "      <th>form</th>\n",
       "      <th>figbass</th>\n",
       "      <th>changes</th>\n",
       "      <th>relativeroot</th>\n",
       "      <th>phraseend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2/4</td>\n",
       "      <td>127</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Eb</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>V43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2/4</td>\n",
       "      <td>127</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Eb</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2/4</td>\n",
       "      <td>127</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Eb</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>V2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2/4</td>\n",
       "      <td>127</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Eb</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/4</td>\n",
       "      <td>127</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Eb</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 chord altchord  measure  beat  totbeat timesig   op    no  mov  \\\n",
       "0         0.0     R      NaN      1.0   1.0      1.0     2/4  127  12.0  1.0   \n",
       "1         1.0   V43      NaN      NaN   1.5      3.5     2/4  127  12.0  1.0   \n",
       "2         NaN     I      NaN      3.0   1.0      5.0     2/4  127  12.0  1.0   \n",
       "3         3.0    V2      NaN      4.0   1.5      7.5     2/4  127  12.0  1.0   \n",
       "4         4.0    I6      NaN      5.0   1.0      NaN     2/4  127  12.0  1.0   \n",
       "\n",
       "   length global_key local_key pedal numeral form  figbass changes  \\\n",
       "0     2.5         Eb         I   NaN       I  NaN      NaN     NaN   \n",
       "1     1.5         Eb         I   NaN       V  NaN      NaN     NaN   \n",
       "2     2.5         Eb         I   NaN       I  NaN      NaN     NaN   \n",
       "3     1.5         Eb         I   NaN       V  NaN      NaN     NaN   \n",
       "4     1.0         Eb         I   NaN       I  NaN      NaN     NaN   \n",
       "\n",
       "  relativeroot  phraseend  \n",
       "0          NaN      False  \n",
       "1          NaN      False  \n",
       "2          NaN      False  \n",
       "3          NaN      False  \n",
       "4          NaN      False  "
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_p_A40chEUPn"
   },
   "outputs": [],
   "source": [
    "#df=df[df.op==127]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3lvB-FVkEUPw"
   },
   "outputs": [],
   "source": [
    "corpus=df.chord.values\n",
    "total_words = len(corpus) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Htw10b_EtchP",
    "outputId": "65392404-c8e7-49fe-a65d-c8246698fb74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'V43', 'I', ..., 'I', 'V', 'I\\\\\\\\\\\\\\\\'], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d0pdIDj_EUP3"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "input_sequences = []\n",
    "token_list = tokenizer.texts_to_sequences(corpus)\n",
    "token_list = list(itertools.chain(*token_list))\n",
    "for i in range(1, len(token_list)):\n",
    "    n_gram_sequence = token_list[:i+1]\n",
    "    input_sequences.append(n_gram_sequence)\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "label=np_utils.to_categorical(label)\n",
    "new_input=np.reshape(input_sequences,(input_sequences.shape[0],input_sequences.shape[1],1))\n",
    "new_pred=np.reshape(predictors,(predictors.shape[0],predictors.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GFK6sCsLEUP8"
   },
   "outputs": [],
   "source": [
    "input_sequences2 = []\n",
    "token_list = tokenizer.texts_to_sequences(corpus)\n",
    "token_list = list(itertools.chain(*token_list))\n",
    "for i in range(1, len(token_list)):\n",
    "    n_gram_sequence2 = token_list[i:i+10]\n",
    "    input_sequences2.append(n_gram_sequence2)\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences2 = np.array(pad_sequences(input_sequences2, maxlen=10, padding='pre'))\n",
    "predictors2, label2 = input_sequences2[:,:-1],input_sequences2[:,-1]\n",
    "label2=np_utils.to_categorical(label2)\n",
    "new_input2=np.reshape(input_sequences2,(input_sequences2.shape[0],input_sequences2.shape[1],1))\n",
    "new_pred2=np.reshape(predictors2,(predictors2.shape[0],predictors2.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gBlcJkRcofk0",
    "outputId": "5e0941bf-5b9d-4391-a8ca-aba427334b86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29852, 29853)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O9cEGxqAEUQD",
    "outputId": "6ccac777-368d-4ba9-e0ad-932f06662193"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29852, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gjxhCh46EUQJ",
    "outputId": "c49dcd2b-c2d4-4e65-b44e-6596d98b17e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2362,)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ohY4KhwwEUQj",
    "outputId": "fb4bc936-7fd4-4d6f-80eb-ac2d02e85adf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>chord</th>\n",
       "      <th>altchord</th>\n",
       "      <th>measure</th>\n",
       "      <th>beat</th>\n",
       "      <th>totbeat</th>\n",
       "      <th>timesig</th>\n",
       "      <th>op</th>\n",
       "      <th>no</th>\n",
       "      <th>mov</th>\n",
       "      <th>length</th>\n",
       "      <th>global_key</th>\n",
       "      <th>local_key</th>\n",
       "      <th>pedal</th>\n",
       "      <th>numeral</th>\n",
       "      <th>form</th>\n",
       "      <th>figbass</th>\n",
       "      <th>changes</th>\n",
       "      <th>relativeroot</th>\n",
       "      <th>phraseend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2/4</td>\n",
       "      <td>127</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Eb</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>V43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2/4</td>\n",
       "      <td>127</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Eb</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2/4</td>\n",
       "      <td>127</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Eb</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>V2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2/4</td>\n",
       "      <td>127</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Eb</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/4</td>\n",
       "      <td>127</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Eb</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 chord altchord  measure  beat  totbeat timesig   op    no  mov  \\\n",
       "0         0.0     R      NaN      1.0   1.0      1.0     2/4  127  12.0  1.0   \n",
       "1         1.0   V43      NaN      NaN   1.5      3.5     2/4  127  12.0  1.0   \n",
       "2         NaN     I      NaN      3.0   1.0      5.0     2/4  127  12.0  1.0   \n",
       "3         3.0    V2      NaN      4.0   1.5      7.5     2/4  127  12.0  1.0   \n",
       "4         4.0    I6      NaN      5.0   1.0      NaN     2/4  127  12.0  1.0   \n",
       "\n",
       "   length global_key local_key pedal numeral form  figbass changes  \\\n",
       "0     2.5         Eb         I   NaN       I  NaN      NaN     NaN   \n",
       "1     1.5         Eb         I   NaN       V  NaN      NaN     NaN   \n",
       "2     2.5         Eb         I   NaN       I  NaN      NaN     NaN   \n",
       "3     1.5         Eb         I   NaN       V  NaN      NaN     NaN   \n",
       "4     1.0         Eb         I   NaN       I  NaN      NaN     NaN   \n",
       "\n",
       "  relativeroot  phraseend  \n",
       "0          NaN      False  \n",
       "1          NaN      False  \n",
       "2          NaN      False  \n",
       "3          NaN      False  \n",
       "4          NaN      False  "
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qdI-XBmiEUQn",
    "outputId": "f84529e1-7caa-4401-e149-173a2e64bc72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rVfpovA4EUQv",
    "outputId": "1616c312-1634-486b-9741-57d395d08122"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1882 samples, validate on 471 samples\n",
      "Epoch 1/10\n",
      "1882/1882 [==============================] - 180s - loss: 3.9590 - acc: 0.0537 - val_loss: 3.8226 - val_acc: 0.1125\n",
      "Epoch 2/10\n",
      "1882/1882 [==============================] - 188s - loss: 3.6921 - acc: 0.1015 - val_loss: 3.4668 - val_acc: 0.1465\n",
      "Epoch 3/10\n",
      "1882/1882 [==============================] - 219s - loss: 3.3735 - acc: 0.1344 - val_loss: 3.2202 - val_acc: 0.1614\n",
      "Epoch 4/10\n",
      "1882/1882 [==============================] - 200s - loss: 3.2528 - acc: 0.1344 - val_loss: 3.1602 - val_acc: 0.1783\n",
      "Epoch 5/10\n",
      "1882/1882 [==============================] - 169s - loss: 3.2185 - acc: 0.1403 - val_loss: 3.1312 - val_acc: 0.1805\n",
      "Epoch 6/10\n",
      "1882/1882 [==============================] - 408s - loss: 3.2010 - acc: 0.1467 - val_loss: 3.1172 - val_acc: 0.1805\n",
      "Epoch 7/10\n",
      "1882/1882 [==============================] - 180s - loss: 3.1998 - acc: 0.1467 - val_loss: 3.1053 - val_acc: 0.1805\n",
      "Epoch 8/10\n",
      "1882/1882 [==============================] - 171s - loss: 3.1914 - acc: 0.1488 - val_loss: 3.0982 - val_acc: 0.1805\n",
      "Epoch 9/10\n",
      "1882/1882 [==============================] - 171s - loss: 3.1772 - acc: 0.1482 - val_loss: 3.0922 - val_acc: 0.1805\n",
      "Epoch 10/10\n",
      "1882/1882 [==============================] - 171s - loss: 3.1850 - acc: 0.1498 - val_loss: 3.0885 - val_acc: 0.1805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb53a5d390>"
      ]
     },
     "execution_count": 131,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(20, return_sequences=False, input_shape=(new_input.shape[0],1)))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(LSTM(25, return_sequences=False))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(LSTM(512, return_sequences=False))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(total_words,activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(new_pred, label, nb_epoch=10, verbose=1,validation_split=0.2)#, callbacks=[earlystop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1785
    },
    "colab_type": "code",
    "id": "cQAnSCrgEUQ1",
    "outputId": "04d606e3-dc04-4cb4-edc8-90c99063c8ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23881 samples, validate on 5971 samples\n",
      "Epoch 1/50\n",
      "23881/23881 [==============================] - 113s 5ms/step - loss: 3.1232 - acc: 0.1739 - val_loss: 3.0581 - val_acc: 0.2072\n",
      "Epoch 2/50\n",
      "23881/23881 [==============================] - 105s 4ms/step - loss: 3.0437 - acc: 0.1873 - val_loss: 3.0222 - val_acc: 0.2139\n",
      "Epoch 3/50\n",
      "23881/23881 [==============================] - 107s 4ms/step - loss: 3.0143 - acc: 0.1917 - val_loss: 2.9934 - val_acc: 0.2154\n",
      "Epoch 4/50\n",
      "23881/23881 [==============================] - 106s 4ms/step - loss: 2.9864 - acc: 0.1973 - val_loss: 2.9770 - val_acc: 0.2145\n",
      "Epoch 5/50\n",
      "23881/23881 [==============================] - 106s 4ms/step - loss: 2.9549 - acc: 0.2019 - val_loss: 2.9395 - val_acc: 0.2186\n",
      "Epoch 6/50\n",
      "23881/23881 [==============================] - 105s 4ms/step - loss: 2.9260 - acc: 0.2075 - val_loss: 2.9222 - val_acc: 0.2264\n",
      "Epoch 7/50\n",
      "23881/23881 [==============================] - 103s 4ms/step - loss: 2.9105 - acc: 0.2126 - val_loss: 2.9083 - val_acc: 0.2276\n",
      "Epoch 8/50\n",
      "23881/23881 [==============================] - 103s 4ms/step - loss: 2.8948 - acc: 0.2175 - val_loss: 2.9099 - val_acc: 0.2236\n",
      "Epoch 9/50\n",
      "23881/23881 [==============================] - 106s 4ms/step - loss: 2.8780 - acc: 0.2225 - val_loss: 2.8974 - val_acc: 0.2341\n",
      "Epoch 10/50\n",
      "23881/23881 [==============================] - 103s 4ms/step - loss: 2.8686 - acc: 0.2240 - val_loss: 2.8872 - val_acc: 0.2358\n",
      "Epoch 11/50\n",
      "23881/23881 [==============================] - 100s 4ms/step - loss: 2.8546 - acc: 0.2286 - val_loss: 2.8909 - val_acc: 0.2376\n",
      "Epoch 12/50\n",
      "23881/23881 [==============================] - 100s 4ms/step - loss: 2.8423 - acc: 0.2299 - val_loss: 2.8849 - val_acc: 0.2385\n",
      "Epoch 13/50\n",
      "23881/23881 [==============================] - 102s 4ms/step - loss: 2.8305 - acc: 0.2329 - val_loss: 2.8825 - val_acc: 0.2397\n",
      "Epoch 14/50\n",
      "23881/23881 [==============================] - 114s 5ms/step - loss: 2.8154 - acc: 0.2344 - val_loss: 2.8855 - val_acc: 0.2390\n",
      "Epoch 15/50\n",
      "23881/23881 [==============================] - 109s 5ms/step - loss: 2.8070 - acc: 0.2382 - val_loss: 2.8794 - val_acc: 0.2470\n",
      "Epoch 16/50\n",
      "23881/23881 [==============================] - 108s 5ms/step - loss: 2.7941 - acc: 0.2414 - val_loss: 2.8863 - val_acc: 0.2403\n",
      "Epoch 17/50\n",
      "23881/23881 [==============================] - 109s 5ms/step - loss: 2.7784 - acc: 0.2447 - val_loss: 2.8802 - val_acc: 0.2432\n",
      "Epoch 18/50\n",
      "23881/23881 [==============================] - 108s 5ms/step - loss: 2.7677 - acc: 0.2470 - val_loss: 2.8812 - val_acc: 0.2425\n",
      "Epoch 19/50\n",
      "23881/23881 [==============================] - 107s 4ms/step - loss: 2.7518 - acc: 0.2471 - val_loss: 2.8769 - val_acc: 0.2475\n",
      "Epoch 20/50\n",
      "23881/23881 [==============================] - 104s 4ms/step - loss: 2.7391 - acc: 0.2547 - val_loss: 2.8881 - val_acc: 0.2474\n",
      "Epoch 21/50\n",
      "23881/23881 [==============================] - 105s 4ms/step - loss: 2.7282 - acc: 0.2543 - val_loss: 2.8854 - val_acc: 0.2492\n",
      "Epoch 22/50\n",
      "23881/23881 [==============================] - 105s 4ms/step - loss: 2.7118 - acc: 0.2551 - val_loss: 2.8875 - val_acc: 0.2477\n",
      "Epoch 23/50\n",
      "23881/23881 [==============================] - 106s 4ms/step - loss: 2.7009 - acc: 0.2612 - val_loss: 2.8895 - val_acc: 0.2514\n",
      "Epoch 24/50\n",
      "23881/23881 [==============================] - 109s 5ms/step - loss: 2.6810 - acc: 0.2619 - val_loss: 2.9021 - val_acc: 0.2489\n",
      "Epoch 25/50\n",
      "23881/23881 [==============================] - 111s 5ms/step - loss: 2.6717 - acc: 0.2645 - val_loss: 2.8985 - val_acc: 0.2454\n",
      "Epoch 26/50\n",
      "23881/23881 [==============================] - 114s 5ms/step - loss: 2.6547 - acc: 0.2694 - val_loss: 2.8914 - val_acc: 0.2507\n",
      "Epoch 27/50\n",
      "23881/23881 [==============================] - 110s 5ms/step - loss: 2.6417 - acc: 0.2694 - val_loss: 2.9017 - val_acc: 0.2445\n",
      "Epoch 28/50\n",
      "23881/23881 [==============================] - 104s 4ms/step - loss: 2.6252 - acc: 0.2761 - val_loss: 2.9070 - val_acc: 0.2437\n",
      "Epoch 29/50\n",
      "23881/23881 [==============================] - 103s 4ms/step - loss: 2.6123 - acc: 0.2754 - val_loss: 2.9120 - val_acc: 0.2442\n",
      "Epoch 30/50\n",
      "23881/23881 [==============================] - 105s 4ms/step - loss: 2.5892 - acc: 0.2795 - val_loss: 2.9163 - val_acc: 0.2376\n",
      "Epoch 31/50\n",
      "23881/23881 [==============================] - 105s 4ms/step - loss: 2.5766 - acc: 0.2819 - val_loss: 2.9285 - val_acc: 0.2373\n",
      "Epoch 32/50\n",
      "23881/23881 [==============================] - 105s 4ms/step - loss: 2.5538 - acc: 0.2878 - val_loss: 2.9393 - val_acc: 0.2383\n",
      "Epoch 33/50\n",
      "23881/23881 [==============================] - 108s 5ms/step - loss: 2.5424 - acc: 0.2909 - val_loss: 2.9448 - val_acc: 0.2376\n",
      "Epoch 34/50\n",
      "23881/23881 [==============================] - 115s 5ms/step - loss: 2.5308 - acc: 0.2917 - val_loss: 2.9486 - val_acc: 0.2366\n",
      "Epoch 35/50\n",
      "23881/23881 [==============================] - 114s 5ms/step - loss: 2.5128 - acc: 0.2927 - val_loss: 2.9575 - val_acc: 0.2402\n",
      "Epoch 36/50\n",
      "23881/23881 [==============================] - 107s 4ms/step - loss: 2.4931 - acc: 0.3010 - val_loss: 2.9651 - val_acc: 0.2321\n",
      "Epoch 37/50\n",
      "23881/23881 [==============================] - 102s 4ms/step - loss: 2.4811 - acc: 0.3017 - val_loss: 2.9803 - val_acc: 0.2346\n",
      "Epoch 38/50\n",
      "23881/23881 [==============================] - 103s 4ms/step - loss: 2.4597 - acc: 0.3056 - val_loss: 2.9825 - val_acc: 0.2351\n",
      "Epoch 39/50\n",
      "23881/23881 [==============================] - 105s 4ms/step - loss: 2.4451 - acc: 0.3089 - val_loss: 2.9781 - val_acc: 0.2360\n",
      "Epoch 40/50\n",
      "23881/23881 [==============================] - 106s 4ms/step - loss: 2.4324 - acc: 0.3127 - val_loss: 2.9939 - val_acc: 0.2340\n",
      "Epoch 41/50\n",
      "23881/23881 [==============================] - 105s 4ms/step - loss: 2.4124 - acc: 0.3178 - val_loss: 3.0107 - val_acc: 0.2239\n",
      "Epoch 42/50\n",
      "23881/23881 [==============================] - 108s 5ms/step - loss: 2.4019 - acc: 0.3200 - val_loss: 3.0274 - val_acc: 0.2226\n",
      "Epoch 43/50\n",
      "23881/23881 [==============================] - 114s 5ms/step - loss: 2.3834 - acc: 0.3252 - val_loss: 3.0313 - val_acc: 0.2254\n",
      "Epoch 44/50\n",
      "23881/23881 [==============================] - 114s 5ms/step - loss: 2.3692 - acc: 0.3283 - val_loss: 3.0361 - val_acc: 0.2301\n",
      "Epoch 45/50\n",
      "23881/23881 [==============================] - 104s 4ms/step - loss: 2.3589 - acc: 0.3298 - val_loss: 3.0525 - val_acc: 0.2266\n",
      "Epoch 46/50\n",
      "23881/23881 [==============================] - 98s 4ms/step - loss: 2.3450 - acc: 0.3353 - val_loss: 3.0665 - val_acc: 0.2234\n",
      "Epoch 47/50\n",
      "23881/23881 [==============================] - 100s 4ms/step - loss: 2.3267 - acc: 0.3329 - val_loss: 3.0656 - val_acc: 0.2192\n",
      "Epoch 48/50\n",
      "23881/23881 [==============================] - 101s 4ms/step - loss: 2.3119 - acc: 0.3426 - val_loss: 3.0829 - val_acc: 0.2186\n",
      "Epoch 49/50\n",
      "23881/23881 [==============================] - 102s 4ms/step - loss: 2.2944 - acc: 0.3440 - val_loss: 3.0954 - val_acc: 0.2221\n",
      "Epoch 50/50\n",
      "23881/23881 [==============================] - 104s 4ms/step - loss: 2.2767 - acc: 0.3481 - val_loss: 3.1086 - val_acc: 0.2137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f84e8f4ada0>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(Embedding(total_words, 10, input_length=9))\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(new_pred2.shape[1],1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True),input_shape=(9,1)))\n",
    "#model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "#model.add(LSTM(512, return_sequences=True))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(total_words,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(new_pred2, label2, nb_epoch=50, verbose=1,validation_split=0.2)#, callbacks=[earlystop])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1918
    },
    "colab_type": "code",
    "id": "np9bTp6rEUQ6",
    "outputId": "e8554131-e732-45f1-9cc8-28f8281de59d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23881 samples, validate on 5971 samples\n",
      "Epoch 1/50\n",
      "23881/23881 [==============================] - 124s 5ms/step - loss: 3.1221 - acc: 0.1709 - val_loss: 3.0371 - val_acc: 0.2033\n",
      "Epoch 2/50\n",
      "23881/23881 [==============================] - 110s 5ms/step - loss: 3.0422 - acc: 0.1879 - val_loss: 3.0270 - val_acc: 0.2132\n",
      "Epoch 3/50\n",
      "23881/23881 [==============================] - 107s 4ms/step - loss: 3.0055 - acc: 0.1943 - val_loss: 3.0000 - val_acc: 0.2140\n",
      "Epoch 4/50\n",
      "23881/23881 [==============================] - 101s 4ms/step - loss: 2.9743 - acc: 0.1979 - val_loss: 2.9614 - val_acc: 0.2140\n",
      "Epoch 5/50\n",
      "23881/23881 [==============================] - 103s 4ms/step - loss: 2.9344 - acc: 0.2055 - val_loss: 2.9430 - val_acc: 0.2187\n",
      "Epoch 6/50\n",
      "23881/23881 [==============================] - 102s 4ms/step - loss: 2.9063 - acc: 0.2126 - val_loss: 2.9068 - val_acc: 0.2244\n",
      "Epoch 7/50\n",
      "23881/23881 [==============================] - 105s 4ms/step - loss: 2.8865 - acc: 0.2212 - val_loss: 2.9078 - val_acc: 0.2273\n",
      "Epoch 8/50\n",
      "23881/23881 [==============================] - 107s 4ms/step - loss: 2.8663 - acc: 0.2238 - val_loss: 2.8926 - val_acc: 0.2301\n",
      "Epoch 9/50\n",
      "23881/23881 [==============================] - 109s 5ms/step - loss: 2.8509 - acc: 0.2277 - val_loss: 2.8876 - val_acc: 0.2427\n",
      "Epoch 10/50\n",
      "23881/23881 [==============================] - 111s 5ms/step - loss: 2.8347 - acc: 0.2307 - val_loss: 2.8936 - val_acc: 0.2348\n",
      "Epoch 11/50\n",
      "23881/23881 [==============================] - 111s 5ms/step - loss: 2.8205 - acc: 0.2344 - val_loss: 2.8819 - val_acc: 0.2388\n",
      "Epoch 12/50\n",
      "23881/23881 [==============================] - 106s 4ms/step - loss: 2.8011 - acc: 0.2376 - val_loss: 2.8774 - val_acc: 0.2392\n",
      "Epoch 13/50\n",
      "23881/23881 [==============================] - 104s 4ms/step - loss: 2.7848 - acc: 0.2422 - val_loss: 2.8837 - val_acc: 0.2412\n",
      "Epoch 14/50\n",
      "23881/23881 [==============================] - 101s 4ms/step - loss: 2.7610 - acc: 0.2481 - val_loss: 2.8748 - val_acc: 0.2479\n",
      "Epoch 15/50\n",
      "23881/23881 [==============================] - 102s 4ms/step - loss: 2.7434 - acc: 0.2482 - val_loss: 2.8834 - val_acc: 0.2430\n",
      "Epoch 16/50\n",
      "23881/23881 [==============================] - 105s 4ms/step - loss: 2.7140 - acc: 0.2565 - val_loss: 2.8822 - val_acc: 0.2457\n",
      "Epoch 17/50\n",
      "23881/23881 [==============================] - 104s 4ms/step - loss: 2.6933 - acc: 0.2594 - val_loss: 2.9019 - val_acc: 0.2460\n",
      "Epoch 18/50\n",
      "23881/23881 [==============================] - 104s 4ms/step - loss: 2.6680 - acc: 0.2636 - val_loss: 2.8991 - val_acc: 0.2415\n",
      "Epoch 19/50\n",
      "23881/23881 [==============================] - 115s 5ms/step - loss: 2.6442 - acc: 0.2705 - val_loss: 2.9168 - val_acc: 0.2422\n",
      "Epoch 20/50\n",
      "23881/23881 [==============================] - 112s 5ms/step - loss: 2.6202 - acc: 0.2772 - val_loss: 2.9200 - val_acc: 0.2378\n",
      "Epoch 21/50\n",
      "23881/23881 [==============================] - 113s 5ms/step - loss: 2.5889 - acc: 0.2828 - val_loss: 2.9305 - val_acc: 0.2380\n",
      "Epoch 22/50\n",
      "23881/23881 [==============================] - 105s 4ms/step - loss: 2.5495 - acc: 0.2906 - val_loss: 2.9571 - val_acc: 0.2361\n",
      "Epoch 23/50\n",
      "23881/23881 [==============================] - 102s 4ms/step - loss: 2.5290 - acc: 0.2954 - val_loss: 2.9698 - val_acc: 0.2321\n",
      "Epoch 24/50\n",
      "23881/23881 [==============================] - 102s 4ms/step - loss: 2.4972 - acc: 0.3021 - val_loss: 2.9855 - val_acc: 0.2288\n",
      "Epoch 25/50\n",
      "23881/23881 [==============================] - 105s 4ms/step - loss: 2.4650 - acc: 0.3136 - val_loss: 3.0005 - val_acc: 0.2266\n",
      "Epoch 26/50\n",
      "23881/23881 [==============================] - 105s 4ms/step - loss: 2.4333 - acc: 0.3169 - val_loss: 3.0178 - val_acc: 0.2279\n",
      "Epoch 27/50\n",
      "23881/23881 [==============================] - 105s 4ms/step - loss: 2.4015 - acc: 0.3219 - val_loss: 3.0474 - val_acc: 0.2243\n",
      "Epoch 28/50\n",
      "23881/23881 [==============================] - 110s 5ms/step - loss: 2.3739 - acc: 0.3303 - val_loss: 3.0622 - val_acc: 0.2248\n",
      "Epoch 29/50\n",
      "23881/23881 [==============================] - 112s 5ms/step - loss: 2.3348 - acc: 0.3397 - val_loss: 3.0906 - val_acc: 0.2132\n",
      "Epoch 30/50\n",
      "22496/23881 [===========================>..] - ETA: 5s - loss: 2.2950 - acc: 0.3481"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-82bab019aee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_pred2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, callbacks=[earlystop])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(Embedding(total_words, 10, input_length=9))\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=(new_pred2.shape[1],1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True),input_shape=(9,1)))\n",
    "#model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "#model.add(LSTM(512, return_sequences=True))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(total_words,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(new_pred2, label2, nb_epoch=50, verbose=1,validation_split=0.2)#, callbacks=[earlystop])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "CU6FTaNYEUQ9",
    "outputId": "7aacb4f7-b2d6-42e5-d5ce-a38241e63aa1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23881 samples, validate on 5971 samples\n",
      "Epoch 1/50\n",
      "23881/23881 [==============================] - 88s 4ms/step - loss: 3.1173 - acc: 0.1705 - val_loss: 3.0809 - val_acc: 0.1971\n",
      "Epoch 2/50\n",
      "23881/23881 [==============================] - 84s 4ms/step - loss: 3.0392 - acc: 0.1768 - val_loss: 3.0518 - val_acc: 0.2010\n",
      "Epoch 3/50\n",
      "23881/23881 [==============================] - 84s 4ms/step - loss: 3.0168 - acc: 0.1867 - val_loss: 3.0306 - val_acc: 0.2035\n",
      "Epoch 4/50\n",
      "23881/23881 [==============================] - 84s 4ms/step - loss: 3.0000 - acc: 0.1888 - val_loss: 3.0261 - val_acc: 0.2060\n",
      "Epoch 5/50\n",
      "23881/23881 [==============================] - 91s 4ms/step - loss: 2.9856 - acc: 0.1928 - val_loss: 3.0066 - val_acc: 0.2083\n",
      "Epoch 6/50\n",
      "23881/23881 [==============================] - 84s 3ms/step - loss: 2.9710 - acc: 0.1966 - val_loss: 3.0035 - val_acc: 0.2137\n",
      "Epoch 7/50\n",
      "23881/23881 [==============================] - 84s 4ms/step - loss: 2.9610 - acc: 0.1975 - val_loss: 2.9888 - val_acc: 0.2144\n",
      "Epoch 8/50\n",
      "23881/23881 [==============================] - 82s 3ms/step - loss: 2.9489 - acc: 0.1988 - val_loss: 2.9855 - val_acc: 0.2144\n",
      "Epoch 9/50\n",
      "23881/23881 [==============================] - 79s 3ms/step - loss: 2.9380 - acc: 0.1996 - val_loss: 2.9778 - val_acc: 0.2142\n",
      "Epoch 10/50\n",
      "23881/23881 [==============================] - 79s 3ms/step - loss: 2.9249 - acc: 0.2013 - val_loss: 2.9756 - val_acc: 0.2181\n",
      "Epoch 11/50\n",
      "23881/23881 [==============================] - 79s 3ms/step - loss: 2.9102 - acc: 0.2013 - val_loss: 2.9731 - val_acc: 0.2174\n",
      "Epoch 12/50\n",
      "23881/23881 [==============================] - 80s 3ms/step - loss: 2.8954 - acc: 0.2046 - val_loss: 2.9587 - val_acc: 0.2227\n",
      "Epoch 13/50\n",
      "23881/23881 [==============================] - 81s 3ms/step - loss: 2.8796 - acc: 0.2077 - val_loss: 2.9546 - val_acc: 0.2248\n",
      "Epoch 14/50\n",
      "23881/23881 [==============================] - 84s 4ms/step - loss: 2.8640 - acc: 0.2170 - val_loss: 2.9477 - val_acc: 0.2253\n",
      "Epoch 15/50\n",
      "23881/23881 [==============================] - 83s 3ms/step - loss: 2.8507 - acc: 0.2209 - val_loss: 2.9523 - val_acc: 0.2328\n",
      "Epoch 16/50\n",
      "23881/23881 [==============================] - 84s 4ms/step - loss: 2.8406 - acc: 0.2241 - val_loss: 2.9354 - val_acc: 0.2264\n",
      "Epoch 17/50\n",
      "23881/23881 [==============================] - 89s 4ms/step - loss: 2.8302 - acc: 0.2251 - val_loss: 2.9454 - val_acc: 0.2254\n",
      "Epoch 18/50\n",
      "23881/23881 [==============================] - 82s 3ms/step - loss: 2.8172 - acc: 0.2270 - val_loss: 2.9409 - val_acc: 0.2279\n",
      "Epoch 19/50\n",
      "19712/23881 [=======================>......] - ETA: 14s - loss: 2.8082 - acc: 0.2268"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(Embedding(total_words, 10, input_length=9))\n",
    "model.add(LSTM(80, return_sequences=True, input_shape=(new_pred2.shape[1],1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=False),input_shape=(9,1)))\n",
    "#model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "#model.add(LSTM(512, return_sequences=True))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(LSTM(64, return_sequences=False))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(total_words,activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(new_pred2, label2, nb_epoch=50, verbose=1,validation_split=0.2)#, callbacks=[earlystop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cB73jEIAEURF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "POD_E8kxEURJ",
    "outputId": "699e9079-efce-4aa9-db68-524be987731e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Lr8n2ufEURO",
    "outputId": "a97dd165-ceab-426e-c2c5-f8564a7d1c7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29905, 29906)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ELRedAizEURT",
    "outputId": "ddb4842b-28d2-428a-bfa3-420bab44c6c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29906"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "atLLzdPVEURY"
   },
   "outputs": [],
   "source": [
    "#split by opus\n",
    "#split by measures\n",
    "#upload the updated data\n",
    "#distr of chords\n",
    "#split "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NN experimentation_Liana .ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
